{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremyvanvalkenburg/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/jeremyvanvalkenburg/anaconda/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Embedding, Flatten, Dense, Conv2D, BatchNormalization\n",
    "from keras import Sequential\n",
    "from sklearn.externals import joblib\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv's\n",
    "df_base = pd.read_csv(\"~/Repositories/datasets/analytics/a_base.csv\")\n",
    "df_qgiv = pd.read_csv(\"~/Repositories/datasets/analytics/analytics_qgiv.csv\")\n",
    "df_qgiv_base = pd.read_csv(\"~/Repositories/datasets/analytics/a_qgiv_base_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge base ID into qgiv dataframe\n",
    "df_qgiv = df_qgiv.merge(df_qgiv_base, left_on=\"id\", right_on=\"id_x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge base dataframe into qgiv dataframe\n",
    "df = df_qgiv.merge(df_base, left_on=\"base\", right_on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.tm_stamp.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'pledges_count', u'events_count', u'events_priv_count',\n",
       "       u'restrictions', u'amounts', u'ded_types', u'opt_ded_flds',\n",
       "       u'req_ded_flds', u'opt_fields', u'req_fields', u'pledge_active',\n",
       "       u'donation_active', u'multirestriction_system', u'min_amount',\n",
       "       u'max_amount', u'show_amount', u'permit_anonymous', u'permit_recurring',\n",
       "       u'permit_other_amount', u'permit_create_own_pledge', u'collect_company',\n",
       "       u'collect_phone', u'collect_optin', u'collect_captcha',\n",
       "       u'collect_address_mobile', u'enable_donorlogins', u'enable_sms',\n",
       "       u'default_recurring_frequency', u'event_stats', u'new_rec_volume',\n",
       "       u'new_rec_count', u'new_rec_volume.1', u'reg_count', u'dl_trans_volume',\n",
       "       u'dl_trans_count', u'dl_new_rec_count', u'dl_new_rec_volume', u'id_x',\n",
       "       u'org_x', u'id_x', u'base', u'id_y', u'org_y', u'sic', u'ein',\n",
       "       u'visits', u'mobile_visits', u'vt_trans_count', u'don_form_trans_count',\n",
       "       u'kiosk_trans_count', u'p2p_trans_count', u'mobile_trans_count',\n",
       "       u'mobilevt_trans_count', u'sms_trans_count', u'fb_trans_count',\n",
       "       u'vt_trans_vol', u'don_form_trans_vol', u'kiosk_trans_vol',\n",
       "       u'p2p_trans_vol', u'mobile_trans_vol', u'mobilevt_trans_vol',\n",
       "       u'sms_trans_vol', u'fb_trans_vol', u'tm_stamp', u'one_time_trans_count',\n",
       "       u'one_time_trans_vol', u'rec_trans_count', u'rec_trans_vol', u'product',\n",
       "       u'form'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'org', u'sic', u'ein', u'visits', u'mobile_visits',\n",
       "       u'vt_trans_count', u'don_form_trans_count', u'kiosk_trans_count',\n",
       "       u'p2p_trans_count', u'mobile_trans_count', u'mobilevt_trans_count',\n",
       "       u'sms_trans_count', u'fb_trans_count', u'vt_trans_vol',\n",
       "       u'don_form_trans_vol', u'kiosk_trans_vol', u'p2p_trans_vol',\n",
       "       u'mobile_trans_vol', u'mobilevt_trans_vol', u'sms_trans_vol',\n",
       "       u'fb_trans_vol', u'tm_stamp', u'one_time_trans_count',\n",
       "       u'one_time_trans_vol', u'rec_trans_count', u'rec_trans_vol', u'product',\n",
       "       u'form', u'form_cat', u'form_0', u'form_1', u'form_2', u'form_3',\n",
       "       u'form_4', u'form_5', u'form_6', u'form_7', u'form_8', u'form_9',\n",
       "       u'form_10', u'form_11', u'form_12', u'form_13', u'form_14', u'form_15',\n",
       "       u'form_16', u'form_17', u'form_18', u'form_19', u'form_20', u'form_21',\n",
       "       u'form_22', u'form_23', u'form_24', u'form_25', u'form_26', u'form_27',\n",
       "       u'form_28', u'form_29'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.columns\n",
    "# form embedding columns added out of cell order here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up some unnecessary columns\n",
    "df.drop([\"id_x\", \"base\", \"id_y\", \"org_y\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['conversion'] = df['don_form_trans_count'] / (df['visits']+df['mobile_visits'])\n",
    "df['conversion'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breakout datetime components\n",
    "df['tm_stamp'] = pd.to_datetime(df['tm_stamp'])\n",
    "df['year'] = df['tm_stamp'].dt.year\n",
    "df['month'] = df['tm_stamp'].dt.month\n",
    "df['day'] = df['tm_stamp'].dt.day\n",
    "df['hour'] = df['tm_stamp'].dt.hour\n",
    "df['weekofyear'] = df['tm_stamp'].dt.weekofyear\n",
    "df['dayofweek'] = df['tm_stamp'].dt.dayofweek\n",
    "df['dayofyear'] = df['tm_stamp'].dt.dayofyear\n",
    "df['quarter'] = df['tm_stamp'].dt.quarter\n",
    "\n",
    "df['is_month_start'] = df['tm_stamp'].dt.is_month_start\n",
    "df['is_month_end'] = df['tm_stamp'].dt.is_month_end\n",
    "df['is_quarter_start'] = df['tm_stamp'].dt.is_quarter_start\n",
    "df['is_quarter_end'] = df['tm_stamp'].dt.is_quarter_end\n",
    "df['is_year_start'] = df['tm_stamp'].dt.is_year_start\n",
    "df['is_year_end'] = df['tm_stamp'].dt.is_year_end\n",
    "\n",
    "df.drop('tm_stamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cols = ['year', 'month', 'day', 'hour', 'weekofyear', 'dayofweek', 'dayofyear', 'quarter', \n",
    "           'is_month_start', 'is_month_end', 'is_quarter_start', 'is_quarter_end', 'is_year_start',\n",
    "          'is_year_end']\n",
    "for c in dt_cols:\n",
    "    df[c] = df[c].astype('category').cat.codes\n",
    "df['collect_captcha'] = df['collect_captcha'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    8592979\n",
       " 0     238870\n",
       " 1     153093\n",
       " 2      15058\n",
       "Name: weekofyear, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weekofyear'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrs_core = ['opt_fields', 'req_fields', 'donation_active', 'multirestriction_system', \n",
    "             'restrictions', 'permit_other_amount', 'collect_captcha', 'form']\n",
    "\n",
    "ftrs = ['opt_fields', 'req_fields', 'donation_active', 'multirestriction_system', 'restrictions', \n",
    "        'permit_other_amount', 'collect_captcha', 'day', 'month', 'restrictionsXmultirestriction', \n",
    "        'restrictions^2', 'restrictions^2Xmultirestriction', 'restrictions^3', 'restrictions^3Xmultirestriction', \n",
    "        'opt_fields^2', 'opt_fields^3', 'req_fields^2', 'req_fields^3', 'fields', 'fields^2', 'fields^3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick examination of core features\n",
    "\n",
    "Here we'll do a brief refresher on the core (non-engineered) chosen features with a look at principally related features that were omitted in the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core = df[(df['visits']>0)|(df['mobile_visits']>0)][ftrs_core+['conversion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opt_fields</th>\n",
       "      <th>req_fields</th>\n",
       "      <th>donation_active</th>\n",
       "      <th>multirestriction_system</th>\n",
       "      <th>restrictions</th>\n",
       "      <th>permit_other_amount</th>\n",
       "      <th>collect_captcha</th>\n",
       "      <th>conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>409903</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409910</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409958</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410032</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        opt_fields  req_fields  donation_active  multirestriction_system  \\\n",
       "409903           0           0                1                        0   \n",
       "409910           0           0                1                        0   \n",
       "409958           0           0                1                        0   \n",
       "410008           0           0                1                        0   \n",
       "410032           0           0                0                        0   \n",
       "\n",
       "        restrictions  permit_other_amount collect_captcha  conversion  \n",
       "409903             6                    1               0    0.083333  \n",
       "409910             7                    1               0    0.000000  \n",
       "409958             5                    1               0    0.000000  \n",
       "410008             0                    1               0    0.000000  \n",
       "410032             0                    0               0    0.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_core.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embeddings and add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(ftr, target, dim):\n",
    "    X_train = np.array(ftr).reshape(len(ftr), 1)\n",
    "    \n",
    "    # create the embedding\n",
    "    mdl = Sequential()\n",
    "    mdl.add(Embedding(dim[0], dim[1], input_length=1))\n",
    "    mdl.add(Flatten())\n",
    "    mdl.add(Dense(1, activation='relu'))\n",
    "    mdl.compile('rmsprop', 'mse')\n",
    "    \n",
    "    # train the embedding\n",
    "    mdl.fit(X_train, target, epochs=10, batch_size=128, verbose=0)\n",
    "    \n",
    "    # return the latent features\n",
    "    return mdl.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = 2\n",
    "float(u + 1) / float(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on opt_fields\n",
      "\tcreating embedding of dimension (15, 8)\n",
      "Working on req_fields\n",
      "\tcreating embedding of dimension (10, 6)\n",
      "Working on donation_active\n",
      "\tcreating embedding of dimension (2, 2)\n",
      "Working on multirestriction_system\n",
      "\tcreating embedding of dimension (2, 2)\n",
      "Working on restrictions\n",
      "\tcreating embedding of dimension (44, 23)\n",
      "Working on permit_other_amount\n",
      "\tcreating embedding of dimension (2, 2)\n",
      "Working on collect_captcha\n",
      "\tcreating embedding of dimension (1, 1)\n"
     ]
    }
   ],
   "source": [
    "target = 'conversion'\n",
    "df_core = df_core.copy()\n",
    "cat_ftrs = ['opt_fields', 'req_fields', 'donation_active', 'multirestriction_system',\n",
    "           'restrictions', 'permit_other_amount', 'collect_captcha']\n",
    "embedding_lookup_tables = {}\n",
    "\n",
    "for c in cat_ftrs:\n",
    "    print(\"Working on {}\".format(c))\n",
    "    df_core[c] = df_core[c].astype('category').cat.codes\n",
    "\n",
    "    # define our embedding dimensions\n",
    "    unique_values = len(df_core[c].unique())\n",
    "    dim = (unique_values, int(math.ceil(float(unique_values + 1) / float(2))))\n",
    "\n",
    "    print(\"\\tcreating embedding of dimension {}\".format(dim))\n",
    "    embedding_lookup_tables[c] = generate_embedding(df_core[c], df_core['conversion'], dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.72454433e-02, -7.51600601e-05,  3.06813158e-02, -6.48003258e-03,\n",
       "       -1.32987285e-02,  4.84039001e-02, -2.72805374e-02, -1.34822624e-02,\n",
       "        7.79448962e-03, -1.44388974e-02,  4.75697592e-03,  4.39986587e-02,\n",
       "       -2.42316276e-02, -4.00250033e-03,  1.66943409e-02, -1.88743416e-02,\n",
       "       -1.55542763e-02,  1.10865943e-02, -3.05083301e-02, -6.98660559e-04,\n",
       "        2.20815856e-02, -3.45096923e-02], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_lookup_tables['restrictions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding embedding as features for donation_active\n",
      "adding embedding as features for restrictions\n",
      "adding embedding as features for collect_captcha\n",
      "adding embedding as features for req_fields\n",
      "adding embedding as features for opt_fields\n",
      "adding embedding as features for permit_other_amount\n",
      "adding embedding as features for multirestriction_system\n"
     ]
    }
   ],
   "source": [
    "new_ftrs = []\n",
    "for e in embedding_lookup_tables:\n",
    "    print(\"adding embedding as features for {}\".format(e))\n",
    "    for new_col_i in range(embedding_lookup_tables[e].shape[1]):\n",
    "        new_col_label = \"_\".join([e, str(new_col_i)])\n",
    "        df_core[new_col_label] = df_core[c].apply(lambda x: embedding_lookup_tables[e][x][new_col_i])\n",
    "        new_ftrs.append(new_col_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opt_fields</th>\n",
       "      <th>req_fields</th>\n",
       "      <th>donation_active</th>\n",
       "      <th>multirestriction_system</th>\n",
       "      <th>restrictions</th>\n",
       "      <th>permit_other_amount</th>\n",
       "      <th>collect_captcha</th>\n",
       "      <th>conversion</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>opt_fields_5</th>\n",
       "      <th>opt_fields_6</th>\n",
       "      <th>opt_fields_7</th>\n",
       "      <th>permit_other_amount_0</th>\n",
       "      <th>multirestriction_system_0</th>\n",
       "      <th>donation_active_1</th>\n",
       "      <th>restrictions_22</th>\n",
       "      <th>req_fields_5</th>\n",
       "      <th>permit_other_amount_1</th>\n",
       "      <th>multirestriction_system_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001259</td>\n",
       "      <td>0.017701</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>-0.018796</td>\n",
       "      <td>0.030017</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>-0.020324</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>0.047206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001259</td>\n",
       "      <td>0.017701</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>-0.018796</td>\n",
       "      <td>0.030017</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>-0.020324</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>0.047206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001259</td>\n",
       "      <td>0.017701</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>-0.018796</td>\n",
       "      <td>0.030017</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>-0.020324</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>0.047206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001259</td>\n",
       "      <td>0.017701</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>-0.018796</td>\n",
       "      <td>0.030017</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>-0.020324</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>0.047206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001259</td>\n",
       "      <td>0.017701</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>-0.018796</td>\n",
       "      <td>0.030017</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>-0.020324</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>0.047206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      opt_fields  req_fields  donation_active  multirestriction_system  \\\n",
       "3022           1           1                1                        0   \n",
       "3033           1           1                1                        0   \n",
       "3035           3           0                1                        0   \n",
       "3046           0           1                1                        0   \n",
       "3050           2           0                1                        0   \n",
       "\n",
       "      restrictions  permit_other_amount  collect_captcha  conversion  day  \\\n",
       "3022             0                    1                0    0.416667   10   \n",
       "3033             0                    1                0    0.000000   10   \n",
       "3035             5                    1                0    0.000000   10   \n",
       "3046             0                    1                0    0.000000   10   \n",
       "3050             0                    1                0    0.000000   10   \n",
       "\n",
       "      month            ...              opt_fields_5  opt_fields_6  \\\n",
       "3022      1            ...                 -0.001259      0.017701   \n",
       "3033      1            ...                 -0.001259      0.017701   \n",
       "3035      1            ...                 -0.001259      0.017701   \n",
       "3046      1            ...                 -0.001259      0.017701   \n",
       "3050      1            ...                 -0.001259      0.017701   \n",
       "\n",
       "      opt_fields_7  permit_other_amount_0  multirestriction_system_0  \\\n",
       "3022      0.001325              -0.018796                   0.030017   \n",
       "3033      0.001325              -0.018796                   0.030017   \n",
       "3035      0.001325              -0.018796                   0.030017   \n",
       "3046      0.001325              -0.018796                   0.030017   \n",
       "3050      0.001325              -0.018796                   0.030017   \n",
       "\n",
       "      donation_active_1  restrictions_22  req_fields_5  permit_other_amount_1  \\\n",
       "3022           0.007289         0.008139     -0.020324              -0.000665   \n",
       "3033           0.007289         0.008139     -0.020324              -0.000665   \n",
       "3035           0.007289         0.008139     -0.020324              -0.000665   \n",
       "3046           0.007289         0.008139     -0.020324              -0.000665   \n",
       "3050           0.007289         0.008139     -0.020324              -0.000665   \n",
       "\n",
       "      multirestriction_system_1  \n",
       "3022                   0.047206  \n",
       "3033                   0.047206  \n",
       "3035                   0.047206  \n",
       "3046                   0.047206  \n",
       "3050                   0.047206  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_core.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling on embeddings for form features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_core[new_ftrs], df_core['conversion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0260674835779\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = GradientBoostingRegressor()\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0260683568017\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core = df[(df['visits']>0)|(df['mobile_visits']>0)][ftrs_core+['conversion', 'day', 'month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core['restrictionsXmultirestriction'] = df_core['restrictions'] * df_core['multirestriction_system']\n",
    "df_core['restrictions^2'] = df_core['restrictions']**2\n",
    "df_core['restrictions^2Xmultirestriction'] = df_core['restrictions^2'] * df_core['multirestriction_system']\n",
    "df_core['restrictions^3'] = df_core['restrictions']**3\n",
    "df_core['restrictions^3Xmultirestriction'] = df_core['restrictions^3'] * df_core['multirestriction_system']\n",
    "df_core['opt_fields^2'] = df_core['opt_fields']**2\n",
    "df_core['opt_fields^3'] = df_core['opt_fields']**3\n",
    "df_core['req_fields^2'] = df_core['req_fields']**2\n",
    "df_core['req_fields^3'] = df_core['req_fields']**3\n",
    "df_core['fields'] = df_core['opt_fields'] + df_core['req_fields']\n",
    "df_core['fields^2'] = df_core['fields']**2\n",
    "df_core['fields^3'] = df_core['fields']**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_core[ftrs], df_core['conversion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0228926035439\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning with embeddings\n",
    "\n",
    "Looking to beat an MSE of **0.02289**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_core[cat_ftrs], df_core['conversion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = Sequential()\n",
    "mdl.add(Dense(250, activation='sigmoid', input_shape=(len(X_train.columns), 1)))\n",
    "mdl.add(Dense(250, activation='sigmoid'))\n",
    "mdl.add(Dense(250, activation='sigmoid'))\n",
    "mdl.add(Flatten())\n",
    "mdl.add(Dense(1, activation='sigmoid'))\n",
    "mdl.compile('rmsprop', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 7, 250)            500       \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 7, 250)            62750     \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 7, 250)            62750     \n",
      "_________________________________________________________________\n",
      "flatten_51 (Flatten)         (None, 1750)              0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 1)                 1751      \n",
      "=================================================================\n",
      "Total params: 127,751\n",
      "Trainable params: 127,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inp = np.array(X_train.values).reshape(len(X_train), len(X_train.columns), 1)\n",
    "X_test_inp = np.array(X_test.values).reshape(len(X_test), len(X_test.columns), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19079 samples, validate on 6360 samples\n",
      "Epoch 1/1\n",
      "19079/19079 [==============================] - 9s 479us/step - loss: 0.0288 - val_loss: 0.0252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173acd4d0>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train_inp, y_train, epochs=1, validation_data=(X_test_inp, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19079 samples, validate on 6360 samples\n",
      "Epoch 1/10\n",
      "19079/19079 [==============================] - 6s 297us/step - loss: 0.0278 - val_loss: 0.0283\n",
      "Epoch 2/10\n",
      "19079/19079 [==============================] - 6s 300us/step - loss: 0.0272 - val_loss: 0.0270\n",
      "Epoch 3/10\n",
      "19079/19079 [==============================] - 5s 244us/step - loss: 0.0265 - val_loss: 0.0246\n",
      "Epoch 4/10\n",
      "19079/19079 [==============================] - 5s 247us/step - loss: 0.0263 - val_loss: 0.0246\n",
      "Epoch 5/10\n",
      "19079/19079 [==============================] - 5s 248us/step - loss: 0.0262 - val_loss: 0.0247\n",
      "Epoch 6/10\n",
      "19079/19079 [==============================] - 5s 256us/step - loss: 0.0261 - val_loss: 0.0248\n",
      "Epoch 7/10\n",
      "19079/19079 [==============================] - 5s 247us/step - loss: 0.0261 - val_loss: 0.0248\n",
      "Epoch 8/10\n",
      "19079/19079 [==============================] - 5s 251us/step - loss: 0.0261 - val_loss: 0.0260\n",
      "Epoch 9/10\n",
      "19079/19079 [==============================] - 5s 246us/step - loss: 0.0261 - val_loss: 0.0248\n",
      "Epoch 10/10\n",
      "19079/19079 [==============================] - 5s 248us/step - loss: 0.0261 - val_loss: 0.0245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x174472a90>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train_inp, y_train, epochs=10, validation_data=(X_test_inp, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create form embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base['form_cat'] = df_base.form.astype('category').cat.codes\n",
    "df_trn = df_base[df_base.form_cat!=-1][['form_cat', 'conversion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn['conversion'] = df_trn.conversion.apply(lambda x: 0.0000001 if x == 0. else x)\n",
    "df_trn['conversion'] = df_trn['conversion'].replace(np.inf, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.124410e+05\n",
       "mean     3.952223e-03\n",
       "std      4.005100e-02\n",
       "min      1.000000e-07\n",
       "25%      1.000000e-07\n",
       "50%      1.000000e-07\n",
       "75%      1.000000e-07\n",
       "max      1.000000e+00\n",
       "Name: conversion, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.conversion.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 1, 30)             15373230  \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 15,373,261\n",
      "Trainable params: 15,373,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the embedding\n",
    "mdl = Sequential()\n",
    "mdl.add(Embedding(len(df_trn['form_cat']), 30, input_length=1))\n",
    "mdl.add(Flatten())\n",
    "mdl.add(Dense(1, activation='relu'))\n",
    "mdl.compile('rmsprop', 'mse')\n",
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "512441/512441 [==============================] - 470s 918us/step - loss: 0.0016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176be5cd0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the embedding\n",
    "mdl.fit(df_trn['form_cat'].values, df_trn['conversion'].values, epochs=1, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the latent features\n",
    "form_embedding_lookup = mdl.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base['form_cat'] = df_base.form.astype('category').cat.codes\n",
    "for i in range(form_embedding_lookup.shape[1]):\n",
    "    df_base['form_'+str(i)] = df_base['form_cat'].apply(lambda x: form_embedding_lookup[x][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'org', u'sic', u'ein', u'visits', u'mobile_visits',\n",
       "       u'vt_trans_count', u'don_form_trans_count', u'kiosk_trans_count',\n",
       "       u'p2p_trans_count', u'mobile_trans_count', u'mobilevt_trans_count',\n",
       "       u'sms_trans_count', u'fb_trans_count', u'vt_trans_vol',\n",
       "       u'don_form_trans_vol', u'kiosk_trans_vol', u'p2p_trans_vol',\n",
       "       u'mobile_trans_vol', u'mobilevt_trans_vol', u'sms_trans_vol',\n",
       "       u'fb_trans_vol', u'tm_stamp', u'one_time_trans_count',\n",
       "       u'one_time_trans_vol', u'rec_trans_count', u'rec_trans_vol', u'product',\n",
       "       u'form', u'form_cat', u'form_0', u'form_1', u'form_2', u'form_3',\n",
       "       u'form_4', u'form_5', u'form_6', u'form_7', u'form_8', u'form_9',\n",
       "       u'form_10', u'form_11', u'form_12', u'form_13', u'form_14', u'form_15',\n",
       "       u'form_16', u'form_17', u'form_18', u'form_19', u'form_20', u'form_21',\n",
       "       u'form_22', u'form_23', u'form_24', u'form_25', u'form_26', u'form_27',\n",
       "       u'form_28', u'form_29'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_features = [u'form_0', u'form_1', u'form_2', u'form_3',\n",
    "       u'form_4', u'form_5', u'form_6', u'form_7', u'form_8', u'form_9',\n",
    "       u'form_10', u'form_11', u'form_12', u'form_13', u'form_14', u'form_15',\n",
    "       u'form_16', u'form_17', u'form_18', u'form_19', u'form_20', u'form_21',\n",
    "       u'form_22', u'form_23', u'form_24', u'form_25', u'form_26', u'form_27',\n",
    "       u'form_28', u'form_29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"[u'form_0' u'form_1' u'form_2' u'form_3' u'form_4' u'form_5' u'form_6'\\n u'form_7' u'form_8' u'form_9' u'form_10' u'form_11' u'form_12' u'form_13'\\n u'form_14' u'form_15' u'form_16' u'form_17' u'form_18' u'form_19'\\n u'form_20' u'form_21' u'form_22' u'form_23' u'form_24' u'form_25'\\n u'form_26' u'form_27' u'form_28' u'form_29'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-24dd1aef0e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_core\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'visits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mobile_visits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mftrs_core\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conversion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0memb_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jeremyvanvalkenburg/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeremyvanvalkenburg/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeremyvanvalkenburg/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1269\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[u'form_0' u'form_1' u'form_2' u'form_3' u'form_4' u'form_5' u'form_6'\\n u'form_7' u'form_8' u'form_9' u'form_10' u'form_11' u'form_12' u'form_13'\\n u'form_14' u'form_15' u'form_16' u'form_17' u'form_18' u'form_19'\\n u'form_20' u'form_21' u'form_22' u'form_23' u'form_24' u'form_25'\\n u'form_26' u'form_27' u'form_28' u'form_29'] not in index\""
     ]
    }
   ],
   "source": [
    "df_core = df[(df['visits']>0)|(df['mobile_visits']>0)][ftrs_core+['conversion']+emb_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'opt_fields', u'req_fields', u'donation_active',\n",
       "       u'multirestriction_system', u'restrictions', u'permit_other_amount',\n",
       "       u'collect_captcha', u'form', u'conversion', u'form_0', u'form_1',\n",
       "       u'form_2', u'form_3', u'form_4', u'form_5', u'form_6', u'form_7',\n",
       "       u'form_8', u'form_9', u'form_10', u'form_11', u'form_12', u'form_13',\n",
       "       u'form_14', u'form_15', u'form_16', u'form_17', u'form_18', u'form_19',\n",
       "       u'form_20', u'form_21', u'form_22', u'form_23', u'form_24', u'form_25',\n",
       "       u'form_26', u'form_27', u'form_28', u'form_29'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_core.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_core.drop(['form', 'conversion'], axis=1), df_core['conversion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0155423188874\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard (original) model resulted in an MSE of **0.02289** and here we beat that by achieving **0.01554**. This is pretty good but let's see if we can push that further with a relatively simple DNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we want to store the form embedding with ID's\n",
    "# df_core[['form']+emb_features].to_csv(\"~/Repositories/datasets/analytics/form_conversion_embedding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df): 9000000; len(df_core): 833215\n"
     ]
    }
   ],
   "source": [
    "df_emb = pd.read_csv(\"~/Repositories/datasets/analytics/form_conversion_embedding.csv\")\n",
    "df_core = df[(df['visits']>0)|(df['mobile_visits']>0)][ftrs_core+['conversion']]\n",
    "df_core = df_core.merge(df_emb, on=\"form\")\n",
    "print(\"len(df): {}; len(df_core): {}\".format(len(df), len(df_core)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'opt_fields', u'req_fields', u'donation_active',\n",
       "       u'multirestriction_system', u'restrictions', u'permit_other_amount',\n",
       "       u'collect_captcha', u'form', u'conversion', u'form_0', u'form_1',\n",
       "       u'form_2', u'form_3', u'form_4', u'form_5', u'form_6', u'form_7',\n",
       "       u'form_8', u'form_9', u'form_10', u'form_11', u'form_12', u'form_13',\n",
       "       u'form_14', u'form_15', u'form_16', u'form_17', u'form_18', u'form_19',\n",
       "       u'form_20', u'form_21', u'form_22', u'form_23', u'form_24', u'form_25',\n",
       "       u'form_26', u'form_27', u'form_28', u'form_29'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_core.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_core.drop(['form'd, 'conversion'], axis=1), df_core['conversion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = Sequential()\n",
    "mdl.add(Dense(250, activation='relu', input_shape=(len(X_train.columns), 1)))\n",
    "mdl.add(Dense(250, activation='relu'))\n",
    "mdl.add(Dense(250, activation='relu'))\n",
    "mdl.add(Dense(250, activation='relu'))\n",
    "mdl.add(Dense(250, activation='relu'))\n",
    "mdl.add(Flatten())\n",
    "mdl.add(Dense(1, activation='sigmoid'))\n",
    "mdl.compile('rmsprop', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 37, 250)           500       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 37, 250)           62750     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 37, 250)           62750     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 37, 250)           62750     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 37, 250)           62750     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9250)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 9251      \n",
      "=================================================================\n",
      "Total params: 260,751\n",
      "Trainable params: 260,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inp = np.array(X_train).reshape(len(X_train), len(X_train.columns), 1)\n",
    "X_test_inp = np.array(X_test).reshape(len(X_test), len(X_test.columns), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 624911 samples, validate on 208304 samples\n",
      "Epoch 1/1\n",
      "624911/624911 [==============================] - 924s 1ms/step - loss: 0.0203 - val_loss: 0.0178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1264653d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.fit(X_train_inp, y_train.values, epochs=1, validation_data=(X_test_inp, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdl.fit(X_train_inp, y_train.values, epochs=100, validation_data=(X_test_inp, y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At 50 epochs, we reached an MSE of **0.0196** (epoch 49). This is definitely a promising path and the network doesn't appear to be overtraining so let's keep it going and see if we can stabilize under **0.02**.\n",
    "\n",
    "And after 101 epochs we're landing at an MSE of **0.0194**, and reached a minimum within a handful of epochs of the end at **0.0181**. While the improvement has leveled off and slowed quite a bit, it does not yet appear to have bottomed out so there's still improvement to be attained here.\n",
    "\n",
    "___\n",
    "\n",
    "_First training, lost kernel_. \n",
    "\n",
    "___\n",
    "\n",
    "The improvement slowed to a crawl. We might be able to beat the **0.01554** we achieved with the random forest but it's obvious that it will take _a lot_ of training. The random forest model is a good middle step, and can be relied upon as a trial deployment of the embedding lookup while the DNN continues to be developed and tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean form feature modeling w/ hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load & prep data\n",
      "\treading CSV's\n",
      "\tmerge dataframes\n",
      "\tadding conversion & embedding columns\n",
      "\tdata prepped, 37 features of 833215 observations\n"
     ]
    }
   ],
   "source": [
    "ftrs_core = ['opt_fields', 'req_fields', 'donation_active', 'multirestriction_system', \n",
    "             'restrictions', 'permit_other_amount', 'collect_captcha', 'form']\n",
    "\n",
    "print(\"load & prep data\")\n",
    "print(\"\\treading CSV's\")\n",
    "df_base = pd.read_csv(\"~/Repositories/datasets/analytics/a_base.csv\")\n",
    "df_qgiv = pd.read_csv(\"~/Repositories/datasets/analytics/analytics_qgiv.csv\")\n",
    "df_qgiv_base = pd.read_csv(\"~/Repositories/datasets/analytics/a_qgiv_base_id.csv\")\n",
    "\n",
    "print(\"\\tmerge dataframes\")\n",
    "df_qgiv = df_qgiv.merge(df_qgiv_base, left_on=\"id\", right_on=\"id_x\")\n",
    "df = df_qgiv.merge(df_base, left_on=\"base\", right_on=\"id\", how=\"left\")\n",
    "\n",
    "print(\"\\tadding conversion\")\n",
    "df['conversion'] = df['don_form_trans_count'] / (df['visits']+df['mobile_visits'])\n",
    "df['conversion'].fillna(0., inplace=True)\n",
    "df['conversion'].replace(np.inf, 1.)\n",
    "\n",
    "print(\"\\tadding embedding columns\")\n",
    "df_emb = pd.read_csv(\"~/Repositories/datasets/analytics/form_conversion_embedding.csv\")\n",
    "df_core = df[(df['visits']>0)|(df['mobile_visits']>0)][ftrs_core+['conversion']]\n",
    "df_core = df_core.merge(df_emb, on=\"form\")\n",
    "\n",
    "print(\"\\tdata prepped, {} features of {} observations\".format(len(df_core.columns) - 2, len(df_core)))\n",
    "# ...len(columns) - 2 because form ID & conversion are in there but are not to be used as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameter tuning\n",
      "\ttrain/test split\n",
      "\ttrees...\n",
      "\t\t10 trees: MSE: 0.0134294187075\n",
      "\t\t25 trees: MSE: 0.0134282826641\n",
      "\t\t50 trees: MSE: 0.0134259004581\n",
      "\t\t75 trees: MSE: 0.0134250891819\n",
      "\t\t100 trees: MSE: 0.0134260802508\n"
     ]
    }
   ],
   "source": [
    "print(\"hyperparameter tuning\")\n",
    "print(\"\\ttrain/test split\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_core.drop(['form', 'conversion'], axis=1), df_core['conversion'])\n",
    "\n",
    "print(\"\\ttrees...\")\n",
    "for i in [10, 25, 50, 75, 100]:\n",
    "    rf = RandomForestRegressor(n_estimators=i)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"\\t\\t{} trees: MSE: {}\".format(i, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmin samples split...\n",
      "\t\t2 min_samples_split: MSE: 0.0134272272924\n",
      "\t\t3 min_samples_split: MSE: 0.0134290576679\n",
      "\t\t4 min_samples_split: MSE: 0.0134297032152\n",
      "\t\t5 min_samples_split: MSE: 0.013429558535\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tmin samples split...\")\n",
    "for i in [2, 3, 4, 5]:\n",
    "    rf = RandomForestRegressor(min_samples_split=i)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"\\t\\t{} min_samples_split: MSE: {}\".format(i, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmin samples leaf...\n",
      "\t\t1 min_samples_leaf: MSE: 0.0134276764383\n",
      "\t\t2 min_samples_leaf: MSE: 0.0134302918376\n",
      "\t\t3 min_samples_leaf: MSE: 0.0134293436736\n",
      "\t\t4 min_samples_leaf: MSE: 0.0134327199593\n",
      "\t\t5 min_samples_leaf: MSE: 0.0134306295739\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tmin samples leaf...\")\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    rf = RandomForestRegressor(min_samples_leaf=i)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"\\t\\t{} min_samples_leaf: MSE: {}\".format(i, mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like hyperparameter tuning isn't going to improve anything by a meaningful amount. The default settings for Random Forest Regressor performed better than any of the alterations so _sticking with defaults for all_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit on training data & verify performance\n",
      "\ttrain/test split\n",
      "\tfitting model\n",
      "\tevaluating model\n",
      "\t\tMSE: 0.0133835646281\n"
     ]
    }
   ],
   "source": [
    "print(\"fit on training data & verify performance\")\n",
    "print(\"\\ttrain/test split\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_core.drop(['form', 'conversion'], axis=1), df_core['conversion'])\n",
    "\n",
    "print(\"\\tfitting model\")\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\tevaluating model\")\n",
    "y_pred = rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"\\t\\tMSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with embeddings and form settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load & prep data\n",
      "\treading CSV's\n",
      "\tmerge dataframes\n",
      "\tadding conversion & embedding columns\n",
      "\tdata prepped, 47 features of 833215 observations\n"
     ]
    }
   ],
   "source": [
    "ftrs = ['pledge_active', 'donation_active', 'multirestriction_system', 'min_amount',\n",
    "       'max_amount', 'show_amount', 'permit_anonymous', 'permit_recurring',\n",
    "       'permit_other_amount', 'permit_create_own_pledge', 'collect_company',\n",
    "       'collect_phone', 'collect_optin', 'collect_captcha',\n",
    "       'collect_address_mobile', 'enable_donorlogins', 'enable_sms', 'form']\n",
    "\n",
    "print(\"load & prep data\")\n",
    "print(\"\\treading CSV's\")\n",
    "df_base = pd.read_csv(\"~/Repositories/datasets/analytics/a_base.csv\")\n",
    "df_qgiv = pd.read_csv(\"~/Repositories/datasets/analytics/analytics_qgiv.csv\")\n",
    "df_qgiv_base = pd.read_csv(\"~/Repositories/datasets/analytics/a_qgiv_base_id.csv\")\n",
    "\n",
    "print(\"\\tmerge dataframes\")\n",
    "df_qgiv = df_qgiv.merge(df_qgiv_base, left_on=\"id\", right_on=\"id_x\")\n",
    "df = df_qgiv.merge(df_base, left_on=\"base\", right_on=\"id\", how=\"left\")\n",
    "\n",
    "print(\"\\tadding conversion & embedding columns\")\n",
    "df['conversion'] = df['don_form_trans_count'] / (df['visits']+df['mobile_visits'])\n",
    "df['conversion'].fillna(0., inplace=True)\n",
    "df['conversion'].replace(np.inf, 1.)\n",
    "\n",
    "df_emb = pd.read_csv(\"~/Repositories/datasets/analytics/form_conversion_embedding.csv\")\n",
    "df_core = df[(df['visits']>0)|(df['mobile_visits']>0)][ftrs+['conversion']]\n",
    "df_core = df_core.merge(df_emb, on=\"form\")\n",
    "\n",
    "print(\"\\tdata prepped, {} features of {} observations\".format(len(df_core.columns) - 2, len(df_core)))\n",
    "# ...len(columns) - 2 because form & conversion are in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_core.drop(['form', 'conversion'], axis=1), df_core['conversion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0132923321163\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old model MSE: 0.0194061475176\n"
     ]
    }
   ],
   "source": [
    "# let's get the old model MSE\n",
    "df_core = df[(df['visits']>0)|(df['mobile_visits']>0)][ftrs+['conversion']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_core.drop(['form', 'conversion'], axis=1), df_core['conversion'])\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Old model MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the form settings model is seeing the same range of improvement as features, in the 30% to 40% reduction in error. Let's evaluate hyperparameter tuning on this for the sake of thoroughness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameter tuning\n",
      "\ttrain/test split\n",
      "\ttrees...\n",
      "\t\t10 trees: MSE: 0.013467356763\n",
      "\t\t25 trees: MSE: 0.0134631413643\n",
      "\t\t50 trees: MSE: 0.0134624679065\n",
      "\t\t75 trees: MSE: 0.0134620077648\n",
      "\t\t100 trees: MSE: 0.0134621382401\n",
      "\tmin samples split...\n",
      "\t\t2 min_samples_split: MSE: 0.0134636985479\n",
      "\t\t3 min_samples_split: MSE: 0.0134665846582\n",
      "\t\t4 min_samples_split: MSE: 0.0134663590206\n",
      "\t\t5 min_samples_split: MSE: 0.0134651985713\n",
      "\tmin samples leaf...\n",
      "\t\t1 min_samples_leaf: MSE: 0.0134644503534\n",
      "\t\t2 min_samples_leaf: MSE: 0.0134638281396\n",
      "\t\t3 min_samples_leaf: MSE: 0.0134667043315\n",
      "\t\t4 min_samples_leaf: MSE: 0.0134647189421\n",
      "\t\t5 min_samples_leaf: MSE: 0.013466084465\n"
     ]
    }
   ],
   "source": [
    "print(\"hyperparameter tuning\")\n",
    "print(\"\\ttrain/test split\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_core.drop(['form', 'conversion'], axis=1), df_core['conversion'])\n",
    "\n",
    "print(\"\\ttrees...\")\n",
    "for i in [10, 25, 50, 75, 100]:\n",
    "    rf = RandomForestRegressor(n_estimators=i)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"\\t\\t{} trees: MSE: {}\".format(i, mse))\n",
    "print(\"\\tmin samples split...\")\n",
    "for i in [2, 3, 4, 5]:\n",
    "    rf = RandomForestRegressor(min_samples_split=i)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"\\t\\t{} min_samples_split: MSE: {}\".format(i, mse))\n",
    "print(\"\\tmin samples leaf...\")\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    rf = RandomForestRegressor(min_samples_leaf=i)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"\\t\\t{} min_samples_leaf: MSE: {}\".format(i, mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks again like there's no meaningul improvement with hyperparameter tuning so _sticking with defaults_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit on training data & verify performance\n",
      "\ttrain/test split\n",
      "\tfitting model\n",
      "\tevaluating model\n",
      "\t\tMSE: 0.0132296872743\n"
     ]
    }
   ],
   "source": [
    "print(\"fit on training data & verify performance\")\n",
    "print(\"\\ttrain/test split\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_core.drop(['form', 'conversion'], axis=1), df_core['conversion'])\n",
    "\n",
    "print(\"\\tfitting model\")\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\tevaluating model\")\n",
    "y_pred = rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"\\t\\tMSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try training an embedding for these categorical features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
