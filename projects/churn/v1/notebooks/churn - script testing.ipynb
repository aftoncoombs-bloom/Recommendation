{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle as pkl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../../scripts/')\n",
    "from s3_support import *\n",
    "\n",
    "sys.path.insert(1, '../code/')\n",
    "from churn_support import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\treading in logs, integrations, transactions, and orgs\n"
     ]
    }
   ],
   "source": [
    "print(\"\\treading in logs, integrations, transactions, and orgs\")\n",
    "df_orgs = get_dataframe_from_file(\"qgiv-stats-data\", \"organizations.names.csv\")\n",
    "df_logs = redshift_query_read(\"select * from logs\")\n",
    "df_integrations = get_dataframe_from_file(\"qgiv-stats-data\", 'integrations.csv')\n",
    "df_trans = redshift_query_read(\"select * from transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tisolating churned orgs\n",
      "\tgetting P2P org list from transaction history\n",
      "\tfiltering orgs with fewer than 100 transactions\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tisolating churned orgs\")\n",
    "df_churned_orgs = df_orgs[~df_orgs['date_closed'].isnull()]\n",
    "\n",
    "print(\"\\tgetting P2P org list from transaction history\")\n",
    "p2p_orgs = df_trans[df_trans.source=='p2p']['org'].unique().tolist()\n",
    "\n",
    "print(\"\\tfiltering orgs with fewer than 100 transactions\")\n",
    "orgs_trans_counts = df_trans.groupby('org')['id'].count().reset_index()\n",
    "orgs_never_viable = orgs_trans_counts[orgs_trans_counts['id']<100]['org'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tprepping logs data\n",
      "\t\tset message labels and date values\n",
      "\t\taggregate log label values per org per month\n",
      "\t\textract last 12 months of log entries per organization\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tprepping logs data\")\n",
    "print(\"\\t\\tset message labels and date values\")\n",
    "df_logs['created'] = pd.to_datetime(df_logs['created'])\n",
    "df_logs['month'] = df_logs['created'].dt.month\n",
    "df_logs['year'] = df_logs['created'].dt.year\n",
    "df_logs = df_logs[~df_logs['org'].isin(orgs_never_viable)]\n",
    "df_logs['monthyear'] = df_logs.apply(lambda x: str(x['year'])+'/'+str(x['month']), axis=1)\n",
    "df_logs['message_label'] = df_logs['message'].apply(label_log_entry)\n",
    "df_logs = df_logs.merge(pd.get_dummies(df_logs['message_label'],prefix='label'), left_index=True, right_index=True)\n",
    "\n",
    "print(\"\\t\\taggregate log label values per org per month\")\n",
    "message_label_cols = [c for c in df_logs.columns if 'label_' in c]\n",
    "log_agg = df_logs.groupby(['org', 'monthyear'])[message_label_cols].mean().reset_index()\n",
    "\n",
    "print(\"\\t\\textract last 12 months of log entries per organization\")\n",
    "agged_org_data = []\n",
    "log_agg['monthyear'] = pd.to_datetime(log_agg['monthyear'])\n",
    "\n",
    "for o in log_agg['org'].unique():\n",
    "    _agg = log_agg[log_agg['org']==o].copy()\n",
    "    _agg.sort_values('monthyear', ascending=False, inplace=True)\n",
    "    _this_data = _agg.iloc[-12:].copy()\n",
    "    _this_data['reindex'] = 0\n",
    "    counter = 0\n",
    "    for _, r in _this_data.iterrows():\n",
    "        r['reindex'] = counter\n",
    "        agged_org_data.append(r.to_dict())\n",
    "        counter += 1\n",
    "\n",
    "df_agged = pd.DataFrame(agged_org_data)\n",
    "df_agged['churned'] = df_agged['org'].isin(df_churned_orgs['id'].tolist())\n",
    "df_agged = df_agged[df_agged['org']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompiling integrations with logs\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tcompiling integrations with logs\")\n",
    "df_agged['integrations'] = df_agged['org'].isin(df_integrations['org'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "training models\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*20)\n",
    "print(\"training models\")\n",
    "print(\"-\"*20)\n",
    "\n",
    "ftr_cols = [c for c in df_agged.columns if 'label_' in c] + ['integrations']\n",
    "target_col = 'churned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttrain simple model for feature selection\n"
     ]
    }
   ],
   "source": [
    "print(\"\\ttrain simple model for feature selection\")\n",
    "train_X, test_X, train_y, test_y = train_test_split(df_agged[ftr_cols], df_agged[target_col], test_size=0.33)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(train_X, train_y)\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(train_X.columns, rf.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "# isolate the most important features from the simple model for the real model\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "important_ftrs = importances.sort_values(by='Gini-importance').iloc[-10:].reset_index()[\"index\"]\n",
    "# list formatting the important features output\n",
    "important_ftrs = list(important_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tfull model training with best features from simple model\n",
      "\t\treformatting training data for optimized features\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tfull model training with best features from simple model\")\n",
    "print(\"\\t\\treformatting training data for optimized features\")\n",
    "# reformat dataset to include the most important features for the last 12 months of logs so that we have 1 row per organization\n",
    "reformatted_data = []\n",
    "for o in df_agged['org'].unique():\n",
    "    _df = df_agged[df_agged['org']==o][important_ftrs+['org', 'reindex', 'churned']]\n",
    "    \n",
    "    _this_org_data = {}\n",
    "    for _, r in _df.sort_values('reindex', ascending=True).iterrows():\n",
    "        for c in _df.columns:\n",
    "            if 'label_' in c:\n",
    "                _this_org_data[\"month_{}_{}\".format(r['reindex'], c.replace('.0', ''))] = r[c]\n",
    "            elif c not in _this_org_data:\n",
    "                _this_org_data[c] = r[c]\n",
    "    reformatted_data.append(_this_org_data)\n",
    "                \n",
    "df_reformatted = pd.DataFrame(reformatted_data)\n",
    "df_reformatted['integrations'] = df_reformatted['org'].isin(df_integrations['org'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\ttraining full model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\t\\ttraining full model\")\n",
    "train_X, test_X, train_y, test_y = train_test_split(df_reformatted.drop(['org', 'churned', 'reindex'], axis=1).fillna(0.0), df_reformatted[target_col], test_size=0.33)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "predictions and building report\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*20)\n",
    "print(\"predictions and building report\")\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tfiltering to orgs with activity within the past 6 months\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tfiltering to orgs with activity within the past 6 months\")\n",
    "target_active_orgs = df_orgs[df_orgs['status']=='active']['id'].tolist()\n",
    "\n",
    "six_months_ago = datetime.date.today() - datetime.timedelta(6*365/12)\n",
    "df_trans['date'] = pd.to_datetime(df_trans['date'])\n",
    "df_trans_orgdate = df_trans[df_trans['date']>=pd.Timestamp(six_months_ago)][['date', 'org']]\n",
    "df_trans_agg = df_trans_orgdate.groupby('org')['date'].count().reset_index()\n",
    "# narrow org list to active orgs with more than 10 transactions in the last 6 months\n",
    "target_active_orgs = df_trans_agg[(df_trans_agg['date']>=10)&(df_trans_agg['org'].isin(target_active_orgs))]['org'].tolist()\n",
    "\n",
    "# filter to active orgs\n",
    "try:\n",
    "    df_priorpreds = get_dataframe_from_file(\"qgiv-stats-data\", \"churn_preds.csv\")\n",
    "except:\n",
    "    df_priorpreds = pd.DataFrame(columns=['org', 'date_predicted'])\n",
    "    \n",
    "df_reformatted = df_reformatted[df_reformatted['org'].isin(target_active_orgs)]\n",
    "ftrs = df_reformatted[(~df_reformatted['churned'])&(~df_reformatted['org'].isin(df_priorpreds['org'].tolist()))].drop(['churned', 'org', 'reindex'], axis=1).fillna(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tperform prediction\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tperform prediction\")\n",
    "y_pred = rf.predict_proba(ftrs)\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "y_pred_df['org'] = df_reformatted[~df_reformatted['churned']]['org']\n",
    "top_preds = y_pred_df[~y_pred_df['org'].isin(df_priorpreds['org'].tolist())].sort_values(1, ascending=False).head(20).dropna()\n",
    "\n",
    "predicted_orgs = top_preds['org'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tadd predictions to history\n",
      "uploading to S3\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tadd predictions to history\")\n",
    "tdy = datetime.datetime.today()\n",
    "\n",
    "y_preds_df = pd.DataFrame([{'org': o, 'date_predicted': tdy} for o in predicted_orgs])\n",
    "df_priorpreds = df_priorpreds.append(y_preds_df, sort=True)\n",
    "df_priorpreds['org'] = df_priorpreds['org'].astype(int)\n",
    "save_dataframe_to_file(\"qgiv-stats-data\", \"churn_preds.csv\", df_priorpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:\n",
      "----------------------------------------\n",
      "Mississippi's Toughest Kids Foundation (438304)\n",
      "\tintegrations: False\n",
      "\tcancelled recurring (down), set form (down), donated %amount (down), linked transaction (down), changed organization (down), added recipient (up)\n",
      "Exceleration Foundation, Inc. (40979)\n",
      "\tintegrations: False\n",
      "\tcancelled recurring (down), added recipient (down), cloned a new form (down), set form (down), changed organization (down), donated %amount (down), linked transaction (down)\n",
      "Central Florida Speech & Hearing Center (232)\n",
      "\tintegrations: False\n",
      "\tcancelled recurring (down), added recipient (down), cloned a new form (down), changed organization (down), donated %amount (down), linked transaction (down), set form (up)\n",
      "A Rood Awakening, International (436266)\n",
      "\tintegrations: True\n",
      "\tset form (down), cloned a new form (down), changed organization (down), donated %amount (up), linked transaction (up), updated donor information (up)\n",
      "Self Enquiry Life Fellowship (510)\n",
      "\tintegrations: False\n",
      "\tcancelled recurring (down), added recipient (down), cloned a new form (down), changed organization (down), donated %amount (down), linked transaction (down), set form (up)\n",
      "Owl's Hill Nature Sanctuary (45063)\n",
      "\tintegrations: True\n",
      "\tcancelled recurring (down), cloned a new form (down), changed organization (down), added recipient (down), set form (down), donated %amount (up), linked transaction (up)\n",
      "Kids Wish Network, Inc (1350)\n",
      "\tintegrations: True\n",
      "\tcancelled recurring (down), cloned a new form (down), changed organization (down), added recipient (down), set form (down), linked transaction (up)\n",
      "Camp Wingmann Inc. (1766)\n",
      "\tintegrations: False\n",
      "\tcancelled recurring (down), added recipient (down), cloned a new form (down), changed organization (down), donated %amount (down), linked transaction (down), set form (up)\n",
      "St. Joseph's Catholic Church (678)\n",
      "\tintegrations: False\n",
      "\tcancelled recurring (down), added recipient (down), cloned a new form (down), changed organization (down), linked transaction (up), set form (up)\n",
      "Lima Baptist Temple (15304)\n",
      "\tintegrations: False\n",
      "\tcloned a new form (down), donated %amount (down), linked transaction (down), added recipient (up), changed organization (up), cancelled recurring (up)\n",
      "Catch the Stars Foundation - CTSF (808)\n",
      "\tintegrations: False\n",
      "\tcancelled recurring (down), cloned a new form (down), added recipient (down), changed organization (down), linked transaction (down), set form (up), donated %amount (up)\n"
     ]
    }
   ],
   "source": [
    "print(\"Report:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "labels = []\n",
    "for f in ftrs.columns:\n",
    "    if 'month_0' in f:\n",
    "        labels.append(f.replace('month_0_', ''))\n",
    "\n",
    "for o in predicted_orgs:\n",
    "    inp = df_reformatted[df_reformatted['org']==o]\n",
    "    \n",
    "    try:\n",
    "        org_name = df_orgs[df_orgs['id']==int(o)]['org_name'].iloc[0]\n",
    "    except:\n",
    "        org_name = '(Not found)'\n",
    "    \n",
    "    print(\"{} ({})\".format(org_name, int(o)))\n",
    "    label_diffs = {}\n",
    "    for c in inp.drop(['org', 'churned', 'reindex'], axis=1).columns:\n",
    "        if c == 'integrations':\n",
    "            print(\"\\tintegrations: {}\".format(inp[c].iloc[0]))\n",
    "        else:\n",
    "            label_diffs[c] = inp[c].fillna(0).iloc[0] - df_reformatted[c].mean()\n",
    "            \n",
    "    these_vals_means = {}\n",
    "    for l in labels:\n",
    "        these_vals = []\n",
    "        for k in label_diffs.keys():\n",
    "            if l in k:\n",
    "                these_vals.append(label_diffs[k])\n",
    "        \n",
    "        these_vals_means[entry_labels[int(l.replace('label_', ''))]] = np.mean(these_vals)\n",
    "    \n",
    "    decision_statement = []\n",
    "    for e in sorted(these_vals_means.items(), key=lambda kv: kv[1]):\n",
    "        if abs(e[1]) > 0.015:\n",
    "            if e[1] > 0.:\n",
    "                decision_statement.append(\"{} (up)\".format(e[0]))\n",
    "            else:\n",
    "                decision_statement.append(\"{} (down)\".format(e[0]))\n",
    "    print(\"\\t{}\".format(\", \".join(decision_statement)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
