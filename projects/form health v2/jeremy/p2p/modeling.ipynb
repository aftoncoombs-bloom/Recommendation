{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(1, '../../../../scripts/')\n",
    "from s3_support import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based upon the stats and the nature of the product, it would seem that the best approach would be to train separate models for each relevant target: conversion, transaction count, & page views."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load & prep data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''select\n",
    "            date_trunc('week', date) as date,\n",
    "            org,\n",
    "            form,\n",
    "            sum(views) as pageviews\n",
    "        from googleanalytics_traffic\n",
    "            where date>=2018\n",
    "        group by date_trunc('week', date), org, form;'''\n",
    "pageviews = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665076, 20572)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pageviews = pageviews[pageviews['form']!=0]\n",
    "pageviews['date'] = pd.to_datetime(pageviews['date'])\n",
    "len(pageviews), len(pageviews['form'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''select \n",
    "            form, \n",
    "            date_trunc('week', date) as date,\n",
    "            count(id) as count, \n",
    "            sum(amount) as vol\n",
    "        from transactions\n",
    "        where status='A' and date>=2018 and source='p2p'\n",
    "        group by form, date_trunc('week', date)\n",
    "    '''\n",
    "trans = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41835, 4579)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans['date'] = pd.to_datetime(trans['date'])\n",
    "len(trans), len(trans['form'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analytics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with analytics\n",
      "done with analyticsqgiv\n"
     ]
    }
   ],
   "source": [
    "q = \"select * from analytics_weekly where date>=2018\"\n",
    "df_base = redshift_query_read(q)\n",
    "print(\"done with analytics\")\n",
    "\n",
    "q = \"select * from analyticsp2p_weekly where date>=2018\"\n",
    "df_p2p = redshift_query_read(q)\n",
    "print(\"done with analyticsqgiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p_forms = df_p2p['form'].tolist()\n",
    "df_base = df_base[df_base['form'].isin(p2p_forms)]\n",
    "\n",
    "df_analytics = df_base.merge(df_p2p, on=[\"org\", \"form\", \"date\"]).dropna()\n",
    "\n",
    "df_analytics = df_analytics.drop(['org', 'product'], axis=1).groupby(['date', 'form']).sum().reset_index()\n",
    "\n",
    "df_analytics['date'] = pd.to_datetime(df_analytics['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow dataset to forms in p2p analytics\n",
    "pageviews = pageviews[pageviews['form'].isin(p2p_forms)]\n",
    "trans = trans[trans['form'].isin(p2p_forms)]\n",
    "\n",
    "# merge traffic and transactions\n",
    "trans_n_views = trans.merge(pageviews, on=['form', 'date'])\n",
    "trans_n_views.columns = ['form', 'date', 'trans_count', 'trans_vol', 'org', 'pageviews']\n",
    "\n",
    "# add conversion & average trans value\n",
    "trans_n_views['conversion'] = trans_n_views['trans_count'] / trans_n_views['pageviews']\n",
    "trans_n_views['avg_trans'] = trans_n_views['trans_vol'] / trans_n_views['trans_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_an = df_analytics.merge(trans_n_views, on=['form', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modelling all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['date', 'form', 'trans_count', 'trans_vol', 'org', 'pageviews']\n",
    "targets = ['conversion', 'avg_trans']\n",
    "ftrs = [c for c in df_an.columns if c not in targets and c not in drop_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Targeting conversion\n",
      "----------------------------------------\n",
      "Random Forest:\n",
      "\tR2: -80.0971\n",
      "\tMSE: 54.7695\n",
      "\tRMSE: 6.8000\n",
      "GBM\n",
      "\tR2: -23.8027\n",
      "\tMSE: 117.7714\n",
      "\tRMSE: 9.4515\n",
      "\n",
      "Feature importances:\n",
      "\tvt_trans_count: 0.0002\n",
      "\tp2p_trans_count: 0.2842\n",
      "\tp2p_trans_vol: 0.1951\n",
      "\tsms_trans_vol: 0.0090\n",
      "\tsub_reg_count: 0.1364\n",
      "\tteams_count: 0.0131\n",
      "\tdon_volume: 0.0284\n",
      "\tdon_count: 0.0509\n",
      "\tclass_count: 0.0435\n",
      "\tcat_count: 0.0153\n",
      "\tpromo_count: 0.0025\n",
      "\tamt_count: 0.0295\n",
      "\tded_count: 0.0315\n",
      "\tfields: 0.0461\n",
      "\topt_fields: 0.0223\n",
      "\treq_fields: 0.0338\n",
      "\tallows_reg_ind: 0.0133\n",
      "\tallows_teams: 0.0005\n",
      "\tallows_reg_team_create: 0.0092\n",
      "\tallows_reg_team_join: 0.0002\n",
      "\tallows_opt_reg_donation: 0.0055\n",
      "\tallows_pfp_off_don: 0.0082\n",
      "\tallows_tfp_off_don: 0.0014\n",
      "\tsocial_auto: 0.0006\n",
      "\tsponsors_count: 0.0192\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*40)\n",
    "print(\"Targeting conversion\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "rf_r2 = []\n",
    "rf_mse = []\n",
    "rf_rmse = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[ftrs], df_an['conversion'])\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    rf_r2.append(rf.score(X_test, y_test))\n",
    "    rf_mse.append(mse)\n",
    "    rf_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(rf_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(rf_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(rf_rmse)))\n",
    "\n",
    "print(\"GBM\")\n",
    "gb_r2 = []\n",
    "gb_mse = []\n",
    "gb_rmse = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[ftrs], df_an['conversion'])\n",
    "    gb = GradientBoostingRegressor()\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    gb_r2.append(gb.score(X_test, y_test))\n",
    "    gb_mse.append(mse)\n",
    "    gb_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(gb_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(gb_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(gb_rmse)))\n",
    "\n",
    "print()\n",
    "print(\"Feature importances:\")\n",
    "ftr_importances = [c for c in zip(X_test.columns, rf.feature_importances_)]\n",
    "for f in ftr_importances:\n",
    "    if float(\"{:.4f}\".format(f[1])) > 0.:\n",
    "        print(\"\\t{}: {:.4f}\".format(f[0], f[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Targeting average transaction\n",
      "----------------------------------------\n",
      "Random Forest:\n",
      "\tR2: 0.6574\n",
      "\tMSE: 41518.6146\n",
      "\tRMSE: 121.0853\n",
      "GBM\n",
      "\tR2: 0.6756\n",
      "\tMSE: 82546.9944\n",
      "\tRMSE: 203.6237\n",
      "\n",
      "Feature importances:\n",
      "\tvt_trans_count: 0.0001\n",
      "\tp2p_trans_count: 0.1843\n",
      "\tvt_trans_vol: 0.0001\n",
      "\tp2p_trans_vol: 0.3008\n",
      "\tteams_count: 0.0003\n",
      "\tdon_volume: 0.2420\n",
      "\tdon_count: 0.0282\n",
      "\tclass_count: 0.0004\n",
      "\tcat_count: 0.0012\n",
      "\tpromo_count: 0.0382\n",
      "\tamt_count: 0.0230\n",
      "\tded_count: 0.0002\n",
      "\tfields: 0.0738\n",
      "\topt_fields: 0.0002\n",
      "\treq_fields: 0.0781\n",
      "\tallows_reg_ind: 0.0003\n",
      "\tallows_teams: 0.0083\n",
      "\tallows_reg_team_create: 0.0002\n",
      "\tallows_reg_team_join: 0.0001\n",
      "\tallows_opt_reg_donation: 0.0140\n",
      "\tallows_pfp_off_don: 0.0002\n",
      "\tallows_tfp_off_don: 0.0002\n",
      "\tsponsors_count: 0.0058\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*40)\n",
    "print(\"Targeting average transaction\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "rf_r2 = []\n",
    "rf_mse = []\n",
    "rf_rmse = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[ftrs], df_an['avg_trans'])\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    rf_r2.append(rf.score(X_test, y_test))\n",
    "    rf_mse.append(mse)\n",
    "    rf_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(rf_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(rf_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(rf_rmse)))\n",
    "\n",
    "print(\"GBM\")\n",
    "gb_r2 = []\n",
    "gb_mse = []\n",
    "gb_rmse = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[ftrs], df_an['avg_trans'])\n",
    "    gb = GradientBoostingRegressor()\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    gb_r2.append(gb.score(X_test, y_test))\n",
    "    gb_mse.append(mse)\n",
    "    gb_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(gb_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(gb_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(gb_rmse)))\n",
    "\n",
    "print()\n",
    "print(\"Feature importances:\")\n",
    "ftr_importances = [c for c in zip(X_test.columns, rf.feature_importances_)]\n",
    "for f in ftr_importances:\n",
    "    if float(\"{:.4f}\".format(f[1])) > 0.:\n",
    "        print(\"\\t{}: {:.4f}\".format(f[0], f[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Targeting pageviews\n",
      "----------------------------------------\n",
      "Random Forest:\n",
      "\tR2: 0.5916\n",
      "\tMSE: 232741.8900\n",
      "\tRMSE: 472.6694\n",
      "GBM\n",
      "\tR2: 0.6416\n",
      "\tMSE: 217900.5564\n",
      "\tRMSE: 460.8585\n",
      "\n",
      "Feature importances:\n",
      "\tvt_trans_count: 0.0025\n",
      "\tp2p_trans_count: 0.6328\n",
      "\tmobilevt_trans_count: 0.0009\n",
      "\tvt_trans_vol: 0.0021\n",
      "\tp2p_trans_vol: 0.0579\n",
      "\tmobilevt_trans_vol: 0.0004\n",
      "\tsms_trans_vol: 0.0002\n",
      "\tsub_reg_count: 0.0115\n",
      "\tteams_count: 0.0108\n",
      "\tdon_volume: 0.0486\n",
      "\tdon_count: 0.0533\n",
      "\tclass_count: 0.0108\n",
      "\tcat_count: 0.0158\n",
      "\tpromo_count: 0.0125\n",
      "\tamt_count: 0.0226\n",
      "\tded_count: 0.0059\n",
      "\tfields: 0.0063\n",
      "\topt_fields: 0.0029\n",
      "\treq_fields: 0.0087\n",
      "\tallows_reg_ind: 0.0018\n",
      "\tallows_teams: 0.0017\n",
      "\tallows_reg_team_create: 0.0029\n",
      "\tallows_reg_team_join: 0.0042\n",
      "\tallows_opt_reg_donation: 0.0202\n",
      "\tallows_pfp_off_don: 0.0025\n",
      "\tallows_tfp_off_don: 0.0028\n",
      "\tsocial_auto: 0.0008\n",
      "\tcount_posts: 0.0002\n",
      "\tsponsors_count: 0.0561\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*40)\n",
    "print(\"Targeting pageviews\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "rf_r2 = []\n",
    "rf_mse = []\n",
    "rf_rmse = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[ftrs], df_an['pageviews'])\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    rf_r2.append(rf.score(X_test, y_test))\n",
    "    rf_mse.append(mse)\n",
    "    rf_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(rf_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(rf_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(rf_rmse)))\n",
    "\n",
    "print(\"GBM\")\n",
    "gb_r2 = []\n",
    "gb_mse = []\n",
    "gb_rmse = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[ftrs], df_an['pageviews'])\n",
    "    gb = GradientBoostingRegressor()\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    gb_r2.append(gb.score(X_test, y_test))\n",
    "    gb_mse.append(mse)\n",
    "    gb_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(gb_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(gb_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(gb_rmse)))\n",
    "\n",
    "print()\n",
    "print(\"Feature importances:\")\n",
    "ftr_importances = [c for c in zip(X_test.columns, rf.feature_importances_)]\n",
    "for f in ftr_importances:\n",
    "    if float(\"{:.4f}\".format(f[1])) > 0.:\n",
    "        print(\"\\t{}: {:.4f}\".format(f[0], f[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modelling selected features\n",
    "\n",
    "selected by correlations and distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifications, promos, allow teams, categories, \n",
    "# allow reg team join, fields, allow sub regs\n",
    "ftrs = ['sub_reg_count', 'teams_count', 'class_count',\n",
    "             'promo_count', 'allows_teams', 'trans_count',\n",
    "             'trans_vol', 'pageviews', 'cat_count',\n",
    "             'allows_reg_team_join', 'fields']\n",
    "targets = ['conversion', 'avg_trans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Targeting conversion\n",
      "----------------------------------------\n",
      "Random Forest:\n",
      "\tR2: -28.2333\n",
      "\tMSE: 31.5314\n",
      "\tRMSE: 5.0857\n",
      "GBM\n",
      "\tR2: -230.9148\n",
      "\tMSE: 140.4867\n",
      "\tRMSE: 11.2583\n",
      "\n",
      "Feature importances:\n",
      "\tsub_reg_count: 0.0271\n",
      "\tteams_count: 0.0120\n",
      "\tclass_count: 0.0198\n",
      "\tpromo_count: 0.0209\n",
      "\tallows_teams: 0.0001\n",
      "\ttrans_count: 0.4519\n",
      "\ttrans_vol: 0.2857\n",
      "\tpageviews: 0.1062\n",
      "\tcat_count: 0.0382\n",
      "\tallows_reg_team_join: 0.0013\n",
      "\tfields: 0.0368\n",
      "\n",
      "Excluding other targets\n",
      "----------------------------------------\n",
      "Random Forest:\n",
      "\tR2: -0.4725\n",
      "\tMSE: 83.1284\n",
      "\tRMSE: 8.3535\n",
      "GBM\n",
      "\tR2: -28.7386\n",
      "\tMSE: 120.3510\n",
      "\tRMSE: 10.3729\n",
      "\n",
      "Feature importances:\n",
      "\tsub_reg_count: 0.2498\n",
      "\tteams_count: 0.1753\n",
      "\tclass_count: 0.1693\n",
      "\tpromo_count: 0.0478\n",
      "\tallows_teams: 0.0003\n",
      "\tcat_count: 0.0503\n",
      "\tallows_reg_team_join: 0.0006\n",
      "\tfields: 0.3066\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*40)\n",
    "print(\"Targeting conversion\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "rf_r2 = []\n",
    "rf_mse = []\n",
    "rf_rmse = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[ftrs], df_an['conversion'])\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    rf_r2.append(rf.score(X_test, y_test))\n",
    "    rf_mse.append(mse)\n",
    "    rf_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(rf_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(rf_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(rf_rmse)))\n",
    "\n",
    "print(\"GBM\")\n",
    "gb_r2 = []\n",
    "gb_mse = []\n",
    "gb_rmse = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[ftrs], df_an['conversion'])\n",
    "    gb = GradientBoostingRegressor()\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    gb_r2.append(gb.score(X_test, y_test))\n",
    "    gb_mse.append(mse)\n",
    "    gb_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(gb_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(gb_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(gb_rmse)))\n",
    "\n",
    "print()\n",
    "print(\"Feature importances:\")\n",
    "ftr_importances = [c for c in zip(X_test.columns, rf.feature_importances_)]\n",
    "for f in ftr_importances:\n",
    "    print(\"\\t{}: {:.4f}\".format(f[0], f[1]))\n",
    "    \n",
    "\n",
    "print()\n",
    "print(\"Excluding other targets\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "excl_cols = ['trans_count', 'trans_vol', 'pageviews']\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "rf_r2 = []\n",
    "rf_mse = []\n",
    "rf_rmse = []\n",
    "for i in range(10):\n",
    "    these_ftrs = [c for c in ftrs if c not in excl_cols]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[these_ftrs], df_an['conversion'])\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    rf_r2.append(rf.score(X_test, y_test))\n",
    "    rf_mse.append(mse)\n",
    "    rf_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(rf_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(rf_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(rf_rmse)))\n",
    "\n",
    "print(\"GBM\")\n",
    "gb_r2 = []\n",
    "gb_mse = []\n",
    "gb_rmse = []\n",
    "for i in range(10):\n",
    "    these_ftrs = [c for c in ftrs if c not in excl_cols]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[these_ftrs], df_an['conversion'])\n",
    "    gb = GradientBoostingRegressor()\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    gb_r2.append(gb.score(X_test, y_test))\n",
    "    gb_mse.append(mse)\n",
    "    gb_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(gb_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(gb_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(gb_rmse)))\n",
    "\n",
    "print()\n",
    "print(\"Feature importances:\")\n",
    "ftr_importances = [c for c in zip(X_test.columns, rf.feature_importances_)]\n",
    "for f in ftr_importances:\n",
    "    print(\"\\t{}: {:.4f}\".format(f[0], f[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Targeting average transaction\n",
      "----------------------------------------\n",
      "Random Forest:\n",
      "\tR2: 0.4523\n",
      "\tMSE: 65718.1811\n",
      "\tRMSE: 171.5065\n",
      "GBM\n",
      "\tR2: 0.5673\n",
      "\tMSE: 145722.3956\n",
      "\tRMSE: 302.5947\n",
      "\n",
      "Feature importances:\n",
      "\tsub_reg_count: 0.0001\n",
      "\tteams_count: 0.0004\n",
      "\tclass_count: 0.0005\n",
      "\tpromo_count: 0.0651\n",
      "\tallows_teams: 0.0007\n",
      "\ttrans_count: 0.1801\n",
      "\ttrans_vol: 0.5530\n",
      "\tpageviews: 0.0491\n",
      "\tcat_count: 0.0009\n",
      "\tallows_reg_team_join: 0.0005\n",
      "\tfields: 0.1495\n",
      "\n",
      "Excluding other targets\n",
      "----------------------------------------\n",
      "Random Forest:\n",
      "\tR2: -1.7852\n",
      "\tMSE: 166780.0506\n",
      "\tRMSE: 347.5048\n",
      "GBM\n",
      "\tR2: -1.7369\n",
      "\tMSE: 29458.0628\n",
      "\tRMSE: 169.5221\n",
      "\n",
      "Feature importances:\n",
      "\tsub_reg_count: 0.0248\n",
      "\tteams_count: 0.1131\n",
      "\tclass_count: 0.1035\n",
      "\tpromo_count: 0.4915\n",
      "\tallows_teams: 0.0164\n",
      "\tcat_count: 0.1294\n",
      "\tallows_reg_team_join: 0.0251\n",
      "\tfields: 0.0962\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*40)\n",
    "print(\"Targeting average transaction\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "rf_r2 = []\n",
    "rf_mse = []\n",
    "rf_rmse = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[ftrs], df_an['avg_trans'])\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    rf_r2.append(rf.score(X_test, y_test))\n",
    "    rf_mse.append(mse)\n",
    "    rf_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(rf_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(rf_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(rf_rmse)))\n",
    "\n",
    "print(\"GBM\")\n",
    "gb_r2 = []\n",
    "gb_mse = []\n",
    "gb_rmse = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[ftrs], df_an['avg_trans'])\n",
    "    gb = GradientBoostingRegressor()\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    gb_r2.append(gb.score(X_test, y_test))\n",
    "    gb_mse.append(mse)\n",
    "    gb_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(gb_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(gb_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(gb_rmse)))\n",
    "\n",
    "print()\n",
    "print(\"Feature importances:\")\n",
    "ftr_importances = [c for c in zip(X_test.columns, rf.feature_importances_)]\n",
    "for f in ftr_importances:\n",
    "    print(\"\\t{}: {:.4f}\".format(f[0], f[1]))\n",
    "    \n",
    "\n",
    "print()\n",
    "print(\"Excluding other targets\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "excl_cols = ['trans_count', 'trans_vol', 'pageviews']\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "rf_r2 = []\n",
    "rf_mse = []\n",
    "rf_rmse = []\n",
    "for i in range(10):\n",
    "    these_ftrs = [c for c in ftrs if c not in excl_cols]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[these_ftrs], df_an['avg_trans'])\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    rf_r2.append(rf.score(X_test, y_test))\n",
    "    rf_mse.append(mse)\n",
    "    rf_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(rf_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(rf_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(rf_rmse)))\n",
    "\n",
    "print(\"GBM\")\n",
    "gb_r2 = []\n",
    "gb_mse = []\n",
    "gb_rmse = []\n",
    "for i in range(10):\n",
    "    these_ftrs = [c for c in ftrs if c not in excl_cols]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[these_ftrs], df_an['avg_trans'])\n",
    "    gb = GradientBoostingRegressor()\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    gb_r2.append(gb.score(X_test, y_test))\n",
    "    gb_mse.append(mse)\n",
    "    gb_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(gb_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(gb_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(gb_rmse)))\n",
    "\n",
    "print()\n",
    "print(\"Feature importances:\")\n",
    "ftr_importances = [c for c in zip(X_test.columns, rf.feature_importances_)]\n",
    "for f in ftr_importances:\n",
    "    print(\"\\t{}: {:.4f}\".format(f[0], f[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Targeting pageviews\n",
      "----------------------------------------\n",
      "Random Forest:\n",
      "\tR2: 0.9697\n",
      "\tMSE: 22025.5411\n",
      "\tRMSE: 115.2869\n",
      "GBM\n",
      "\tR2: 0.9884\n",
      "\tMSE: 5852.8446\n",
      "\tRMSE: 63.6094\n",
      "\n",
      "Feature importances:\n",
      "\tsub_reg_count: 0.0006\n",
      "\tteams_count: 0.0015\n",
      "\tclass_count: 0.0003\n",
      "\tpromo_count: 0.0005\n",
      "\tallows_teams: 0.0001\n",
      "\ttrans_count: 0.0014\n",
      "\ttrans_vol: 0.0004\n",
      "\tpageviews: 0.9939\n",
      "\tcat_count: 0.0004\n",
      "\tallows_reg_team_join: 0.0000\n",
      "\tfields: 0.0007\n",
      "\n",
      "Excluding other targets\n",
      "----------------------------------------\n",
      "Random Forest:\n",
      "\tR2: 0.1610\n",
      "\tMSE: 533578.7596\n",
      "\tRMSE: 712.9679\n",
      "GBM\n",
      "\tR2: 0.2229\n",
      "\tMSE: 433503.0506\n",
      "\tRMSE: 646.0105\n",
      "\n",
      "Feature importances:\n",
      "\tsub_reg_count: 0.2011\n",
      "\tteams_count: 0.1723\n",
      "\tclass_count: 0.1303\n",
      "\tpromo_count: 0.1432\n",
      "\tallows_teams: 0.0166\n",
      "\tcat_count: 0.1817\n",
      "\tallows_reg_team_join: 0.0423\n",
      "\tfields: 0.1125\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*40)\n",
    "print(\"Targeting pageviews\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "rf_r2 = []\n",
    "rf_mse = []\n",
    "rf_rmse = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[ftrs], df_an['pageviews'])\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    rf_r2.append(rf.score(X_test, y_test))\n",
    "    rf_mse.append(mse)\n",
    "    rf_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(rf_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(rf_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(rf_rmse)))\n",
    "\n",
    "print(\"GBM\")\n",
    "gb_r2 = []\n",
    "gb_mse = []\n",
    "gb_rmse = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[ftrs], df_an['pageviews'])\n",
    "    gb = GradientBoostingRegressor()\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    gb_r2.append(gb.score(X_test, y_test))\n",
    "    gb_mse.append(mse)\n",
    "    gb_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(gb_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(gb_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(gb_rmse)))\n",
    "\n",
    "print()\n",
    "print(\"Feature importances:\")\n",
    "ftr_importances = [c for c in zip(X_test.columns, rf.feature_importances_)]\n",
    "for f in ftr_importances:\n",
    "    print(\"\\t{}: {:.4f}\".format(f[0], f[1]))\n",
    "    \n",
    "\n",
    "print()\n",
    "print(\"Excluding other targets\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "excl_cols = ['trans_count', 'trans_vol', 'pageviews']\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "rf_r2 = []\n",
    "rf_mse = []\n",
    "rf_rmse = []\n",
    "for i in range(10):\n",
    "    these_ftrs = [c for c in ftrs if c not in excl_cols]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[these_ftrs], df_an['pageviews'])\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    rf_r2.append(rf.score(X_test, y_test))\n",
    "    rf_mse.append(mse)\n",
    "    rf_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(rf_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(rf_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(rf_rmse)))\n",
    "\n",
    "print(\"GBM\")\n",
    "gb_r2 = []\n",
    "gb_mse = []\n",
    "gb_rmse = []\n",
    "for i in range(10):\n",
    "    these_ftrs = [c for c in ftrs if c not in excl_cols]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_an[these_ftrs], df_an['pageviews'])\n",
    "    gb = GradientBoostingRegressor()\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred = gb.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    gb_r2.append(gb.score(X_test, y_test))\n",
    "    gb_mse.append(mse)\n",
    "    gb_rmse.append(math.sqrt(mse))\n",
    "    \n",
    "print(\"\\tR2: {:.4f}\".format(np.mean(gb_r2)))\n",
    "print(\"\\tMSE: {:.4f}\".format(np.mean(gb_mse)))\n",
    "print(\"\\tRMSE: {:.4f}\".format(np.mean(gb_rmse)))\n",
    "\n",
    "print()\n",
    "print(\"Feature importances:\")\n",
    "ftr_importances = [c for c in zip(X_test.columns, rf.feature_importances_)]\n",
    "for f in ftr_importances:\n",
    "    print(\"\\t{}: {:.4f}\".format(f[0], f[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modelling selected features and form embedding\n",
    "\n",
    "try form or org embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
