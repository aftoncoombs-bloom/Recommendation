{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../../../scripts/')\n",
    "from s3_support import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load & prep data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''select\n",
    "            date_trunc('week', date) as week,\n",
    "            org,\n",
    "            form,\n",
    "            sum(views) as pageviews\n",
    "        from googleanalytics_traffic\n",
    "            where date >= 2016 and date <= 2019\n",
    "        group by date_trunc('week', date), org, form;'''\n",
    "pageviews = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageviews = pageviews[pageviews['form']!=0]\n",
    "pageviews.sort_values('week', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''select \n",
    "            form, \n",
    "            date_trunc('week', date) as week,\n",
    "            count(id) as count, \n",
    "            sum(amount) as vol\n",
    "        from transactions\n",
    "        where status='A' and date>=2016 and date<=2019\n",
    "        group by form, date_trunc('week', date)\n",
    "    '''\n",
    "trans = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256129, 11558)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans), len(trans['form'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>week</th>\n",
       "      <th>count</th>\n",
       "      <th>vol</th>\n",
       "      <th>org</th>\n",
       "      <th>pageviews</th>\n",
       "      <th>conversion_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>915548</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>5</td>\n",
       "      <td>1525.99</td>\n",
       "      <td>31832</td>\n",
       "      <td>44</td>\n",
       "      <td>0.113636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>526</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>42</td>\n",
       "      <td>2243.80</td>\n",
       "      <td>554</td>\n",
       "      <td>25</td>\n",
       "      <td>1.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43052</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>6</td>\n",
       "      <td>725.00</td>\n",
       "      <td>15283</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     form       week  count      vol    org  pageviews  conversion_rate\n",
       "0  915548 2017-02-06      5  1525.99  31832         44         0.113636\n",
       "1     526 2017-02-06     42  2243.80    554         25         1.680000\n",
       "2   43052 2017-02-06      6   725.00  15283          1         6.000000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans['week'] = pd.to_datetime(trans['week'])\n",
    "trans.sort_values('week', ascending=True, inplace=True)\n",
    "\n",
    "# merge traffic and transactions\n",
    "trans = trans.merge(pageviews, on=['form', 'week'])\n",
    "\n",
    "# calculate conversion rate & change\n",
    "trans['conversion_rate'] = trans['count'] / trans['pageviews']\n",
    "trans.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118784, 2592)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build form growth data for forms with > 12 months of data\n",
    "form_data = None\n",
    "\n",
    "for form in trans['form'].unique():\n",
    "    if form == 0:\n",
    "        continue\n",
    "    this_df = trans[trans['form']==form].copy()\n",
    "    if len(this_df) >= 12:\n",
    "        this_df['count_growth'] = this_df['count'].pct_change()\n",
    "        this_df['vol_growth'] = this_df['vol'].pct_change()\n",
    "        this_df['conversion_growth'] = this_df['conversion_rate'].pct_change()\n",
    "\n",
    "        if form_data is None:\n",
    "            form_data = this_df\n",
    "        else:\n",
    "            form_data = form_data.append(this_df)\n",
    "len(form_data), len(form_data['form'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''select\n",
    "            form,\n",
    "            date_trunc('week', created) as week,\n",
    "            systemtype,\n",
    "            count(id) as count\n",
    "        from logs\n",
    "        where created>=2016 and created <=2019 and form!=0\n",
    "        group by form, systemtype, date_trunc('week', created)'''\n",
    "logs = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161595, 20563)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs), len(logs['form'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>systemtype</th>\n",
       "      <th>form</th>\n",
       "      <th>week</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "systemtype  form       week    0    4    8   11   12   13   15   18 ...    34  \\\n",
       "0              1 2016-05-02  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0 ...   0.0   \n",
       "1              1 2016-05-30  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0 ...   0.0   \n",
       "2              1 2016-06-20  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0 ...   0.0   \n",
       "\n",
       "systemtype   35   36   38   39   40   41   42   43   44  \n",
       "0           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_pvt = pd.pivot_table(logs, index=['form', 'week'], columns='systemtype', values='count').reset_index()\n",
    "logs_pvt.fillna(0, inplace=True)\n",
    "logs_pvt.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>week</th>\n",
       "      <th>form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    4    8   11   12   13   15   18   20   21  ...    36   38   39   40  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "    41   42   43   44       week  form  \n",
       "0  0.0  0.0  0.0  0.0 2016-05-02     1  \n",
       "1  0.0  0.0  0.0  0.0 2016-05-30     1  \n",
       "2  0.0  0.0  0.0  0.0 2016-06-20     1  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxd_month = logs_pvt['week']\n",
    "idxd_form = logs_pvt['form']\n",
    "logs_pct_change = logs_pvt.drop('week', axis=1).groupby('form').pct_change()\n",
    "logs_pct_change['week'] = idxd_month\n",
    "logs_pct_change['form'] = idxd_form\n",
    "logs_pct_change = logs_pct_change.fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "logs_pct_change.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analytics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"select * from analytics_weekly\"\n",
    "df_base = redshift_query_read(q)\n",
    "q = \"select * from analyticsqgiv_weekly\"\n",
    "df_qgiv = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 86)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_base['date'].unique()), len(df_qgiv['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analytics = df_base.merge(df_qgiv, on=[\"org\", \"form\", \"date\"]).dropna()\n",
    "\n",
    "df_analytics = df_analytics.drop(['org', 'product'], axis=1).groupby(['date', 'form']).sum().reset_index()\n",
    "df_analytics['date'] = pd.to_datetime(df_analytics['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1189306, 23750, 86)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_analytics), len(df_analytics['form'].unique()), len(df_analytics['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_analytics = None\n",
    "for form in df_analytics['form'].unique():\n",
    "    this_df = df_analytics[df_analytics['form']==form].copy()\n",
    "    this_df['week'] = this_df['date']\n",
    "\n",
    "    for c in this_df.columns:\n",
    "        if c not in ['date', 'form', 'week']:\n",
    "            this_df[\"{}_pct_change\".format(c)] = this_df[c].pct_change()\n",
    "            \n",
    "    ext_cols = ['form', 'week'] + [c for c in this_df.columns if '_pct_change' in c]\n",
    "    \n",
    "    if agg_analytics is None:\n",
    "        agg_analytics = this_df[ext_cols]\n",
    "    else:\n",
    "        agg_analytics = agg_analytics.append(this_df[ext_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>week</th>\n",
       "      <th>vt_trans_count_pct_change</th>\n",
       "      <th>don_form_trans_count_pct_change</th>\n",
       "      <th>kiosk_trans_count_pct_change</th>\n",
       "      <th>p2p_trans_count_pct_change</th>\n",
       "      <th>mobile_trans_count_pct_change</th>\n",
       "      <th>mobilevt_trans_count_pct_change</th>\n",
       "      <th>sms_trans_count_pct_change</th>\n",
       "      <th>fb_trans_count_pct_change</th>\n",
       "      <th>...</th>\n",
       "      <th>collect_address_mobile_pct_change</th>\n",
       "      <th>enable_donorlogins_pct_change</th>\n",
       "      <th>enable_sms_pct_change</th>\n",
       "      <th>new_rec_volume_pct_change</th>\n",
       "      <th>new_rec_count_pct_change</th>\n",
       "      <th>reg_count_pct_change</th>\n",
       "      <th>dl_trans_volume_pct_change</th>\n",
       "      <th>dl_trans_count_pct_change</th>\n",
       "      <th>dl_new_rec_count_pct_change</th>\n",
       "      <th>dl_new_rec_volume_pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5534</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11106</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>8.081803</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       form       week  vt_trans_count_pct_change  \\\n",
       "0         1 2017-05-08                   0.000000   \n",
       "5534      1 2017-05-15                 100.000000   \n",
       "11106     1 2017-05-22                   1.777778   \n",
       "\n",
       "       don_form_trans_count_pct_change  kiosk_trans_count_pct_change  \\\n",
       "0                                  0.0                           0.0   \n",
       "5534                             100.0                           0.0   \n",
       "11106                              4.5                           0.0   \n",
       "\n",
       "       p2p_trans_count_pct_change  mobile_trans_count_pct_change  \\\n",
       "0                             0.0                            0.0   \n",
       "5534                          0.0                          100.0   \n",
       "11106                         0.0                            3.0   \n",
       "\n",
       "       mobilevt_trans_count_pct_change  sms_trans_count_pct_change  \\\n",
       "0                                  0.0                         0.0   \n",
       "5534                               0.0                         0.0   \n",
       "11106                              0.0                         0.0   \n",
       "\n",
       "       fb_trans_count_pct_change              ...               \\\n",
       "0                            0.0              ...                \n",
       "5534                         0.0              ...                \n",
       "11106                        0.0              ...                \n",
       "\n",
       "       collect_address_mobile_pct_change  enable_donorlogins_pct_change  \\\n",
       "0                                    0.0                            0.0   \n",
       "5534                                 0.0                            0.0   \n",
       "11106                                0.0                           -1.0   \n",
       "\n",
       "       enable_sms_pct_change  new_rec_volume_pct_change  \\\n",
       "0                        0.0                        0.0   \n",
       "5534                     0.0                        0.0   \n",
       "11106                    0.0                      100.0   \n",
       "\n",
       "       new_rec_count_pct_change  reg_count_pct_change  \\\n",
       "0                           0.0              0.000000   \n",
       "5534                        0.0            100.000000   \n",
       "11106                     100.0              5.333333   \n",
       "\n",
       "       dl_trans_volume_pct_change  dl_trans_count_pct_change  \\\n",
       "0                        0.000000                        0.0   \n",
       "5534                   100.000000                      100.0   \n",
       "11106                    8.081803                       11.0   \n",
       "\n",
       "       dl_new_rec_count_pct_change  dl_new_rec_volume_pct_change  \n",
       "0                              0.0                           0.0  \n",
       "5534                           0.0                           0.0  \n",
       "11106                          0.0                           0.0  \n",
       "\n",
       "[3 rows x 54 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_analytics = agg_analytics.fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "agg_analytics.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1189306, 86, 23750)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agg_analytics), len(agg_analytics['week'].unique()), len(agg_analytics['form'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data set\n",
    "dataset = form_data.dropna()[['form', 'week', 'count_growth', 'vol_growth', 'conversion_rate', 'conversion_growth']]\n",
    "dataset = dataset.merge(logs_pct_change, on=['form', 'week'])\n",
    "dataset = dataset.merge(agg_analytics, on=['form', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7031, 1291, 39)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), len(dataset['form'].unique()), len(dataset['week'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['month'] = dataset['week'].dt.month\n",
    "dataset['dayofmonth'] = dataset['week'].dt.day\n",
    "\n",
    "for column in dataset.columns:\n",
    "    if 'growth' in str(column) or 'pct_change' in str(column):\n",
    "        dataset[column] = dataset[column].replace(np.inf, 100.).replace(-np.inf, -100.).fillna(0)\n",
    "dataset.columns = [str(c) for c in dataset.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset length: 7031 rows\n",
      "\n",
      "form: 1291 unique values\n",
      "week: 39 unique values\n",
      "count_growth: 2159 unique values\n",
      "vol_growth: 6360 unique values\n",
      "conversion_rate: 3684 unique values\n",
      "conversion_growth: 5788 unique values\n",
      "11: 188 unique values\n",
      "15: 11 unique values\n",
      "20: 2 unique values\n",
      "21: 47 unique values\n",
      "23: 179 unique values\n",
      "24: 10 unique values\n",
      "27: 2 unique values\n",
      "29: 14 unique values\n",
      "32: 39 unique values\n",
      "34: 119 unique values\n",
      "35: 3 unique values\n",
      "36: 14 unique values\n",
      "38: 3 unique values\n",
      "39: 3 unique values\n",
      "40: 3 unique values\n",
      "41: 3 unique values\n",
      "42: 3 unique values\n",
      "43: 2 unique values\n",
      "44: 5 unique values\n",
      "vt_trans_count_pct_change: 373 unique values\n",
      "don_form_trans_count_pct_change: 1523 unique values\n",
      "kiosk_trans_count_pct_change: 268 unique values\n",
      "mobile_trans_count_pct_change: 603 unique values\n",
      "mobilevt_trans_count_pct_change: 15 unique values\n",
      "sms_trans_count_pct_change: 87 unique values\n",
      "fb_trans_count_pct_change: 14 unique values\n",
      "vt_trans_vol_pct_change: 649 unique values\n",
      "don_form_trans_vol_pct_change: 3865 unique values\n",
      "kiosk_trans_vol_pct_change: 431 unique values\n",
      "mobile_trans_vol_pct_change: 1371 unique values\n",
      "mobilevt_trans_vol_pct_change: 17 unique values\n",
      "sms_trans_vol_pct_change: 147 unique values\n",
      "fb_trans_vol_pct_change: 21 unique values\n",
      "one_time_trans_vol_pct_change: 3865 unique values\n",
      "one_time_trans_count_pct_change: 1523 unique values\n",
      "rec_trans_vol_pct_change: 3662 unique values\n",
      "rec_trans_count_pct_change: 1385 unique values\n",
      "pledges_count_pct_change: 15 unique values\n",
      "events_priv_count_pct_change: 2 unique values\n",
      "restrictions_pct_change: 82 unique values\n",
      "amounts_pct_change: 39 unique values\n",
      "ded_types_pct_change: 8 unique values\n",
      "req_ded_flds_pct_change: 6 unique values\n",
      "opt_fields_pct_change: 15 unique values\n",
      "req_fields_pct_change: 14 unique values\n",
      "pledge_active_pct_change: 3 unique values\n",
      "donation_active_pct_change: 4 unique values\n",
      "multirestriction_system_pct_change: 3 unique values\n",
      "min_amount_pct_change: 28 unique values\n",
      "max_amount_pct_change: 9 unique values\n",
      "permit_anonymous_pct_change: 3 unique values\n",
      "permit_other_amount_pct_change: 3 unique values\n",
      "permit_create_own_pledge_pct_change: 4 unique values\n",
      "collect_company_pct_change: 3 unique values\n",
      "collect_phone_pct_change: 3 unique values\n",
      "collect_optin_pct_change: 5 unique values\n",
      "collect_address_mobile_pct_change: 5 unique values\n",
      "enable_donorlogins_pct_change: 3 unique values\n",
      "enable_sms_pct_change: 3 unique values\n",
      "new_rec_volume_pct_change: 881 unique values\n",
      "new_rec_count_pct_change: 368 unique values\n",
      "reg_count_pct_change: 677 unique values\n",
      "dl_trans_volume_pct_change: 1047 unique values\n",
      "dl_trans_count_pct_change: 530 unique values\n",
      "dl_new_rec_count_pct_change: 74 unique values\n",
      "dl_new_rec_volume_pct_change: 186 unique values\n",
      "month: 9 unique values\n",
      "dayofmonth: 31 unique values\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset length: {} rows\".format(len(dataset)))\n",
    "print()\n",
    "for column in dataset.columns:\n",
    "    unique_val_len = len(dataset[column].unique())\n",
    "    if unique_val_len > 1:\n",
    "        print(\"{}: {} unique values\".format(column, unique_val_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling full feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Flatten, Dense, Conv2D, BatchNormalization\n",
    "from keras import Sequential\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_features = ['form', 'week']\n",
    "target_cols = ['conversion_rate', 'conversion_growth', 'vol_growth', 'count_growth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(features, target, dimensions):\n",
    "    X_train = np.array(features).reshape(len(features), 1)\n",
    "    \n",
    "    # create embedding model\n",
    "    mdl = Sequential()\n",
    "    mdl.add(Embedding(dim[0], dim[1], input_length=1))\n",
    "    mdl.add(Flatten())\n",
    "    mdl.add(Dense(1, activation='relu'))\n",
    "    mdl.compile('rmsprop', 'mse')\n",
    "    \n",
    "    # train embedding model\n",
    "    mdl.fit(X_train, target, epochs=10, batch_size=128, verbose=0)\n",
    "    \n",
    "    # return latent features\n",
    "    return mdl.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list continuous variables and casting to category and generating an embedding \n",
    "# for any feature with fewer than 100 unique values\n",
    "embedding_lookup_tables = {}\n",
    "for t in target_cols:\n",
    "    embedding_lookup_tables[t] = {}\n",
    "continuous_vars = []\n",
    "\n",
    "for column in dataset.columns:\n",
    "    unique_val_len = len(dataset[column].unique())\n",
    "    \n",
    "    if unique_val_len > 1 and str(column) not in drop_cols_features + target_cols:\n",
    "        if unique_val_len <= 100:\n",
    "            # 100 or fewer unique values, treat as category\n",
    "            col_cat_values = dataset[column].astype('category').cat.codes\n",
    "            dataset[column] = col_cat_values\n",
    "\n",
    "            # define embedding\n",
    "            dim = (unique_val_len, int(math.ceil(float(unique_val_len + 1) / float(2))))\n",
    "\n",
    "            for t in target_cols:\n",
    "                embedding_lookup_tables[t][str(column)] = generate_embedding(col_cat_values, dataset[t], dim)\n",
    "        else:\n",
    "            continuous_vars.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandom Forest:\n",
      "\t\tr2: -0.1823561195162361\n",
      "\t\tmse: 38.60357874936636\n",
      "\tGBM:\n",
      "\t\tr2: -0.038198996584297575\n",
      "\t\tmse: 33.53748036552423\n",
      "----------------------------------------\n",
      "conversion_growth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandom Forest:\n",
      "\t\tr2: -1.317451438002779\n",
      "\t\tmse: 44.046966751314805\n",
      "\tGBM:\n",
      "\t\tr2: -0.36392690417969836\n",
      "\t\tmse: 39.7609976107329\n",
      "----------------------------------------\n",
      "vol_growth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandom Forest:\n",
      "\t\tr2: -3.407605770159332\n",
      "\t\tmse: 16283.868368046815\n",
      "\tGBM:\n",
      "\t\tr2: -1.9647261383698764\n",
      "\t\tmse: 13363.708650931432\n",
      "----------------------------------------\n",
      "count_growth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandom Forest:\n",
      "\t\tr2: -0.2487115346696035\n",
      "\t\tmse: 40.85145043119823\n",
      "\tGBM:\n",
      "\t\tr2: -0.09682488479450942\n",
      "\t\tmse: 46.8176380160755\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for target in target_cols:\n",
    "    print(target)\n",
    "    # build dataset for the given target\n",
    "    #     continuous vars + embeddings for this target\n",
    "    target_col = dataset[target]\n",
    "    this_dataset = dataset.drop(drop_cols_features + target_cols, axis=1).copy()\n",
    "    \n",
    "    # set new feature columns for embeddings mapped to the categorical values\n",
    "    new_features = []\n",
    "    for e in embedding_lookup_tables[target]:\n",
    "        for new_col_i in range(embedding_lookup_tables[target][e].shape[1]):\n",
    "            new_col_label = \"_\".join([str(e), str(new_col_i)])\n",
    "            this_dataset[new_col_label] = this_dataset[e].apply(lambda x: embedding_lookup_tables[target][e][x][new_col_i])\n",
    "            new_features.append(new_col_label)\n",
    "    \n",
    "    # collect continuous and embedding features into clean training dataset\n",
    "    this_dataset_clean = this_dataset[new_features + continuous_vars]\n",
    "    this_dataset_clean[target] = target_col\n",
    "    \n",
    "    # train & evaluate\n",
    "    scores = []\n",
    "    mses = []\n",
    "    for i in range(50):\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset_clean.drop(target, axis=1), this_dataset_clean[target])\n",
    "        \n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        \n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\tRandom Forest:\")\n",
    "    print(\"\\t\\tr2: {}\".format(np.mean(scores)))\n",
    "    print(\"\\t\\tmse: {}\".format(np.mean(mses)))\n",
    "    \n",
    "    scores = []\n",
    "    mses = []\n",
    "    for i in range(50):\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset_clean.drop(target, axis=1), this_dataset_clean[target])\n",
    "        \n",
    "        gbm = GradientBoostingRegressor()\n",
    "        gbm.fit(X_train, y_train)\n",
    "        y_pred = gbm.predict(X_test)\n",
    "        \n",
    "        scores.append(gbm.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    print(\"\\tGBM:\")\n",
    "    print(\"\\t\\tr2: {}\".format(np.mean(scores)))\n",
    "    print(\"\\t\\tmse: {}\".format(np.mean(mses)))  \n",
    "    \n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The old model achieved an MSE of **0.01554** with a random forest trained only the forms  to conversion rates rather than every categorical variable. \n",
    "\n",
    "**Original model features**\n",
    "\n",
    "[u'opt_fields', u'req_fields', u'donation_active',\n",
    "       u'multirestriction_system', u'restrictions', u'permit_other_amount',\n",
    "       u'collect_captcha', u'form', u'conversion', u'form_0', u'form_1',\n",
    "       u'form_2', u'form_3', u'form_4', u'form_5', u'form_6', u'form_7',\n",
    "       u'form_8', u'form_9', u'form_10', u'form_11', u'form_12', u'form_13',\n",
    "       u'form_14', u'form_15', u'form_16', u'form_17', u'form_18', u'form_19',\n",
    "       u'form_20', u'form_21', u'form_22', u'form_23', u'form_24', u'form_25',\n",
    "       u'form_26', u'form_27', u'form_28', u'form_29']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling form & date embeddings\n",
    "\n",
    "here we're going to focus the embedding on form and date variables. specifically,\n",
    "\n",
    "- form ID\n",
    "- month\n",
    "- day of month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Flatten, Dense, Conv2D, BatchNormalization\n",
    "from keras import Sequential\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cols = ['form', 'month']\n",
    "target_cols = ['conversion_rate', 'conversion_growth', 'vol_growth', 'count_growth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(features, target, dimensions):\n",
    "    X_train = np.array(features).reshape(len(features), 1)\n",
    "    \n",
    "    # create embedding model\n",
    "    mdl = Sequential()\n",
    "    mdl.add(Embedding(dim[0], dim[1], input_length=1))\n",
    "    mdl.add(Flatten())\n",
    "    mdl.add(Dense(1, activation='relu'))\n",
    "    mdl.compile('rmsprop', 'mse')\n",
    "    \n",
    "    # train embedding model\n",
    "    mdl.fit(X_train, target, epochs=10, batch_size=128, verbose=0)\n",
    "    \n",
    "    # return latent features\n",
    "    return mdl.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# list continuous variables and casting to category and generating an embedding \n",
    "# for any feature with fewer than 100 unique values\n",
    "embedding_lookup_tables = {}\n",
    "for t in target_cols:\n",
    "    embedding_lookup_tables[t] = {}\n",
    "\n",
    "for column in features_cols:\n",
    "    unique_val_len = len(dataset[column].unique())\n",
    "    col_cat_values = dataset[column].astype('category').cat.codes\n",
    "    dataset[column] = col_cat_values\n",
    "\n",
    "    # define embedding\n",
    "    if column == 'form':\n",
    "        dim = (unique_val_len, 30)\n",
    "    else:\n",
    "        dim = (unique_val_len, int(math.ceil(float(unique_val_len + 1) / float(2))))\n",
    "\n",
    "    for t in target_cols:\n",
    "        embedding_lookup_tables[t][column] = generate_embedding(col_cat_values, dataset[t], dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandom Forest:\n",
      "\t\tr2: 0.14794473204469047\n",
      "\t\tmse: 23.620259558393787\n",
      "\tGBM:\n",
      "\t\tr2: 0.24839218012213532\n",
      "\t\tmse: 22.467871449972094\n",
      "----------------------------------------\n",
      "conversion_growth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandom Forest:\n",
      "\t\tr2: -0.29686756079140664\n",
      "\t\tmse: 41.41156531078358\n",
      "\tGBM:\n",
      "\t\tr2: -0.522127151824169\n",
      "\t\tmse: 37.11788093929876\n",
      "----------------------------------------\n",
      "vol_growth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandom Forest:\n",
      "\t\tr2: -1.4842613660420296\n",
      "\t\tmse: 11887.338506571123\n",
      "\tGBM:\n",
      "\t\tr2: -0.6192272764981258\n",
      "\t\tmse: 10416.77993744346\n",
      "----------------------------------------\n",
      "count_growth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRandom Forest:\n",
      "\t\tr2: -0.3691423231236264\n",
      "\t\tmse: 40.61228571587713\n",
      "\tGBM:\n",
      "\t\tr2: -0.1997723109964289\n",
      "\t\tmse: 36.72563805124084\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for target in target_cols:\n",
    "    print(target)\n",
    "    # build dataset for the given target\n",
    "    #     continuous vars + embeddings for this target\n",
    "    target_col = dataset[target]\n",
    "    this_dataset = dataset[features_cols].copy()\n",
    "    \n",
    "    # set new feature columns for embeddings mapped to the categorical values\n",
    "    new_features = []\n",
    "    for e in embedding_lookup_tables[target]:\n",
    "        for new_col_i in range(embedding_lookup_tables[target][e].shape[1]):\n",
    "            new_col_label = \"_\".join([e, str(new_col_i)])\n",
    "            this_dataset[new_col_label] = this_dataset[str(e)].apply(lambda x: embedding_lookup_tables[target][e][x][new_col_i])\n",
    "            new_features.append(new_col_label)\n",
    "    \n",
    "    # collect continuous and embedding features into clean training dataset\n",
    "    this_dataset_clean = this_dataset[new_features]\n",
    "    this_dataset_clean[target] = target_col\n",
    "    \n",
    "    # train & evaluate\n",
    "    scores = []\n",
    "    mses = []\n",
    "    for i in range(50):\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset_clean.drop(target, axis=1), this_dataset_clean[target])\n",
    "        \n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        \n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\tRandom Forest:\")\n",
    "    print(\"\\t\\tr2: {}\".format(np.mean(scores)))\n",
    "    print(\"\\t\\tmse: {}\".format(np.mean(mses)))\n",
    "    \n",
    "    scores = []\n",
    "    mses = []\n",
    "    for i in range(50):\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset_clean.drop(target, axis=1), this_dataset_clean[target])\n",
    "        \n",
    "        gbm = GradientBoostingRegressor()\n",
    "        gbm.fit(X_train, y_train)\n",
    "        y_pred = gbm.predict(X_test)\n",
    "        \n",
    "        scores.append(gbm.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    print(\"\\tGBM:\")\n",
    "    print(\"\\t\\tr2: {}\".format(np.mean(scores)))\n",
    "    print(\"\\t\\tmse: {}\".format(np.mean(mses)))  \n",
    "    \n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
