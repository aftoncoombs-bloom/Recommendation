{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../../../scripts/')\n",
    "from s3_support import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load & prep data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''select\n",
    "            date_trunc('week', date) as week,\n",
    "            org,\n",
    "            form,\n",
    "            sum(views) as pageviews\n",
    "        from googleanalytics_traffic\n",
    "            where date >= 2016 and date <= 2019\n",
    "        group by date_trunc('week', date), org, form;'''\n",
    "pageviews = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageviews = pageviews[pageviews['form']!=0]\n",
    "pageviews.sort_values('week', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''select \n",
    "            form, \n",
    "            date_trunc('week', date) as week,\n",
    "            count(id) as count, \n",
    "            sum(amount) as vol\n",
    "        from transactions\n",
    "        where status='A' and date>=2016 and date<=2019\n",
    "        group by form, date_trunc('week', date)\n",
    "    '''\n",
    "trans = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256129, 11558)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans), len(trans['form'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>week</th>\n",
       "      <th>count</th>\n",
       "      <th>vol</th>\n",
       "      <th>org</th>\n",
       "      <th>pageviews</th>\n",
       "      <th>conversion_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>506</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>2</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>534</td>\n",
       "      <td>9</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>15</td>\n",
       "      <td>833.0</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>0.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106597</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>13</td>\n",
       "      <td>500.0</td>\n",
       "      <td>29769</td>\n",
       "      <td>2</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     form       week  count     vol    org  pageviews  conversion_rate\n",
       "0     506 2017-02-06      2  2500.0    534          9         0.222222\n",
       "1      17 2017-02-06     15   833.0     42         37         0.405405\n",
       "2  106597 2017-02-06     13   500.0  29769          2         6.500000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans['week'] = pd.to_datetime(trans['week'])\n",
    "trans.sort_values('week', ascending=True, inplace=True)\n",
    "\n",
    "# merge traffic and transactions\n",
    "trans = trans.merge(pageviews, on=['form', 'week'])\n",
    "\n",
    "# calculate conversion rate & change\n",
    "trans['conversion_rate'] = trans['count'] / trans['pageviews']\n",
    "trans.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''select\n",
    "            form,\n",
    "            date_trunc('week', created) as week,\n",
    "            systemtype,\n",
    "            count(id) as count\n",
    "        from logs\n",
    "        where created>=2016 and created <=2019 and form!=0\n",
    "        group by form, systemtype, date_trunc('week', created)'''\n",
    "logs = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161595, 20563)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs), len(logs['form'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>systemtype</th>\n",
       "      <th>form</th>\n",
       "      <th>week</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "systemtype  form       week    0    4    8   11   12   13   15   18 ...    34  \\\n",
       "0              1 2016-05-02  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0 ...   0.0   \n",
       "1              1 2016-05-30  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0 ...   0.0   \n",
       "2              1 2016-06-20  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0 ...   0.0   \n",
       "\n",
       "systemtype   35   36   38   39   40   41   42   43   44  \n",
       "0           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_pvt = pd.pivot_table(logs, index=['form', 'week'], columns='systemtype', values='count').reset_index()\n",
    "logs_pvt.fillna(0, inplace=True)\n",
    "logs_pvt.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analytics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"select * from analytics_weekly\"\n",
    "df_base = redshift_query_read(q)\n",
    "q = \"select * from analyticsqgiv_weekly\"\n",
    "df_qgiv = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 86)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_base['date'].unique()), len(df_qgiv['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analytics = df_base.merge(df_qgiv, on=[\"org\", \"form\", \"date\"]).dropna()\n",
    "\n",
    "df_analytics = df_analytics.drop(['org', 'product'], axis=1).groupby(['date', 'form']).sum().reset_index()\n",
    "df_analytics['week'] = pd.to_datetime(df_analytics['date'])\n",
    "df_analytics.drop('date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1189306, 23750, 86)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_analytics), len(df_analytics['form'].unique()), len(df_analytics['week'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>vt_trans_count</th>\n",
       "      <th>don_form_trans_count</th>\n",
       "      <th>kiosk_trans_count</th>\n",
       "      <th>p2p_trans_count</th>\n",
       "      <th>mobile_trans_count</th>\n",
       "      <th>mobilevt_trans_count</th>\n",
       "      <th>sms_trans_count</th>\n",
       "      <th>fb_trans_count</th>\n",
       "      <th>vt_trans_vol</th>\n",
       "      <th>...</th>\n",
       "      <th>enable_donorlogins</th>\n",
       "      <th>enable_sms</th>\n",
       "      <th>new_rec_volume</th>\n",
       "      <th>new_rec_count</th>\n",
       "      <th>reg_count</th>\n",
       "      <th>dl_trans_volume</th>\n",
       "      <th>dl_trans_count</th>\n",
       "      <th>dl_new_rec_count</th>\n",
       "      <th>dl_new_rec_volume</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   form  vt_trans_count  don_form_trans_count  kiosk_trans_count  \\\n",
       "0     1               0                     0                  0   \n",
       "1     2               0                     0                  0   \n",
       "2     3               0                     0                  0   \n",
       "\n",
       "   p2p_trans_count  mobile_trans_count  mobilevt_trans_count  sms_trans_count  \\\n",
       "0                0                   0                     0                0   \n",
       "1                0                   0                     0                0   \n",
       "2                0                   0                     0                0   \n",
       "\n",
       "   fb_trans_count  vt_trans_vol    ...      enable_donorlogins  enable_sms  \\\n",
       "0               0           0.0    ...                       1           0   \n",
       "1               0           0.0    ...                       0           1   \n",
       "2               0           0.0    ...                       0           0   \n",
       "\n",
       "   new_rec_volume  new_rec_count  reg_count  dl_trans_volume  dl_trans_count  \\\n",
       "0             0.0              0          0              0.0               0   \n",
       "1             0.0              0          0              0.0               0   \n",
       "2             0.0              0          0              0.0               0   \n",
       "\n",
       "   dl_new_rec_count  dl_new_rec_volume       week  \n",
       "0                 0                0.0 2017-05-08  \n",
       "1                 0                0.0 2017-05-08  \n",
       "2                 0                0.0 2017-05-08  \n",
       "\n",
       "[3 rows x 54 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analytics.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data set\n",
    "dataset = trans.dropna()[['form', 'week', 'count', 'vol', 'conversion_rate']]\n",
    "dataset = dataset.merge(logs_pvt, on=['form', 'week'], how='outer')\n",
    "dataset = dataset.merge(df_analytics, on=['form', 'week'], how='outer')\n",
    "dataset['month'] = dataset['week'].dt.month\n",
    "dataset.drop('week', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1354583, 140680, 102836, 1189306)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), len(trans.dropna()), len(logs_pvt), len(df_analytics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>count</th>\n",
       "      <th>vol</th>\n",
       "      <th>conversion_rate</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>enable_donorlogins</th>\n",
       "      <th>enable_sms</th>\n",
       "      <th>new_rec_volume</th>\n",
       "      <th>new_rec_count</th>\n",
       "      <th>reg_count</th>\n",
       "      <th>dl_trans_volume</th>\n",
       "      <th>dl_trans_count</th>\n",
       "      <th>dl_new_rec_count</th>\n",
       "      <th>dl_new_rec_volume</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>506</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>15.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106597</td>\n",
       "      <td>13.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     form  count     vol  conversion_rate    0    4    8    11   12   13  \\\n",
       "0     506    2.0  2500.0         0.222222  NaN  NaN  NaN   NaN  NaN  NaN   \n",
       "1      17   15.0   833.0         0.405405  0.0  0.0  0.0   3.0  0.0  0.0   \n",
       "2  106597   13.0   500.0         6.500000  0.0  0.0  0.0  10.0  0.0  0.0   \n",
       "\n",
       "   ...    enable_donorlogins  enable_sms  new_rec_volume  new_rec_count  \\\n",
       "0  ...                   NaN         NaN             NaN            NaN   \n",
       "1  ...                   NaN         NaN             NaN            NaN   \n",
       "2  ...                   NaN         NaN             NaN            NaN   \n",
       "\n",
       "   reg_count  dl_trans_volume  dl_trans_count  dl_new_rec_count  \\\n",
       "0        NaN              NaN             NaN               NaN   \n",
       "1        NaN              NaN             NaN               NaN   \n",
       "2        NaN              NaN             NaN               NaN   \n",
       "\n",
       "   dl_new_rec_volume  month  \n",
       "0                NaN      2  \n",
       "1                NaN      2  \n",
       "2                NaN      2  \n",
       "\n",
       "[3 rows x 85 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140680, 1213903)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[~dataset['conversion_rate'].isna()]), dataset['conversion_rate'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop where conversion rate is NA, fill other NA with 0\n",
    "dataset = dataset[~dataset['conversion_rate'].isna()]\n",
    "dataset.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140680"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling on raw features\n",
    "\n",
    "here we will use the full feature set modeled against conversion rate, transaction volume, and transaction count with no embeddings to form a baseline. we will perform some feature selection in order to put in a minimum effort to improve this model before moving on to more advanced techniques such as more complicated models and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['conversion_rate', 'vol', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion_rate\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.1086\n",
      "\t\tmse: 9.8257\n",
      "\tGBM:\n",
      "\t\tr2: 0.1016\n",
      "\t\tmse: 9.1203\n",
      "----------------------------------------\n",
      "vol\n",
      "\tRandom Forest:\n",
      "\t\tr2: -0.1364\n",
      "\t\tmse: 54355230.4523\n",
      "\tGBM:\n",
      "\t\tr2: 0.3014\n",
      "\t\tmse: 47595863.4427\n",
      "----------------------------------------\n",
      "count\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.6520\n",
      "\t\tmse: 370.9641\n",
      "\tGBM:\n",
      "\t\tr2: 0.5460\n",
      "\t\tmse: 469.0126\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for target in target_cols:\n",
    "    print(target)\n",
    "    \n",
    "    scores = []\n",
    "    mses = []\n",
    "    for i in range(50):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dataset.drop(target_cols, axis=1), dataset[target])\n",
    "\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        \n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    print(\"\\tRandom Forest:\")\n",
    "    print(\"\\t\\tr2: {:.4f}\".format(np.mean(scores)))\n",
    "    print(\"\\t\\tmse: {:.4f}\".format(np.mean(mses)))\n",
    "    \n",
    "    scores = []\n",
    "    mses = []\n",
    "    for i in range(50):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dataset.drop(target_cols, axis=1), dataset[target])\n",
    "\n",
    "        gbm = GradientBoostingRegressor()\n",
    "        gbm.fit(X_train, y_train)\n",
    "        y_pred = gbm.predict(X_test)\n",
    "        \n",
    "        scores.append(gbm.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    print(\"\\tGBM:\")\n",
    "    print(\"\\t\\tr2: {:.4f}\".format(np.mean(scores)))\n",
    "    print(\"\\t\\tmse: {:.4f}\".format(np.mean(mses)))\n",
    "    \n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The volume and transaction count models could prove useful but we are primarily interested in the conversion rate model. Here we see the conversion rate model performed very poorly. The volume and transaction count models however appear to be of fair quality with R2's between .80 and .90. Let's now perform some feature selection to see if we can't improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## automated feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion_rate\n",
      "\tfeature importance threshold: 0.01\n",
      "\tfeatures (11): form, 23, 34, don_form_trans_count, kiosk_trans_vol, one_time_trans_count, rec_trans_vol, rec_trans_count, new_rec_volume, new_rec_count, month\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.0770\n",
      "\t\tmse: 9.5113\n",
      "\tGBM:\n",
      "\t\tr2: 0.0575\n",
      "\t\tmse: 10.5100\n",
      "----------------------------------------\n",
      "\tfeature importance threshold: 0.02\n",
      "\tfeatures (7): form, 23, 34, don_form_trans_count, kiosk_trans_vol, rec_trans_count, month\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.0738\n",
      "\t\tmse: 9.3291\n",
      "\tGBM:\n",
      "\t\tr2: 0.0876\n",
      "\t\tmse: 9.6900\n",
      "----------------------------------------\n",
      "\tfeature importance threshold: 0.05\n",
      "\tfeatures (4): form, 23, rec_trans_count, month\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.0891\n",
      "\t\tmse: 9.5761\n",
      "\tGBM:\n",
      "\t\tr2: 0.0876\n",
      "\t\tmse: 9.9544\n",
      "----------------------------------------\n",
      "\tfeature importance threshold: 0.1\n",
      "\tfeatures (3): form, 23, month\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.0888\n",
      "\t\tmse: 9.7267\n",
      "\tGBM:\n",
      "\t\tr2: 0.0938\n",
      "\t\tmse: 9.6136\n",
      "----------------------------------------\n",
      "\tfeature importance threshold: 0.15\n",
      "\tfeatures (2): form, 23\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.1150\n",
      "\t\tmse: 9.6362\n",
      "\tGBM:\n",
      "\t\tr2: 0.1117\n",
      "\t\tmse: 9.5958\n",
      "----------------------------------------\n",
      "vol\n",
      "\tfeature importance threshold: 0.01\n",
      "\tfeatures (13): form, 11, 23, 34, don_form_trans_vol, kiosk_trans_vol, one_time_trans_vol, rec_trans_vol, amounts, opt_fields, min_amount, collect_phone, month\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: -0.0980\n",
      "\t\tmse: 50838706.5738\n",
      "\tGBM:\n",
      "\t\tr2: 0.3052\n",
      "\t\tmse: 43342117.8308\n",
      "----------------------------------------\n",
      "\tfeature importance threshold: 0.02\n",
      "\tfeatures (11): form, 23, 34, don_form_trans_vol, one_time_trans_vol, rec_trans_vol, amounts, opt_fields, min_amount, collect_phone, month\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: -0.1598\n",
      "\t\tmse: 59460980.1282\n",
      "\tGBM:\n",
      "\t\tr2: 0.2245\n",
      "\t\tmse: 45164862.6193\n",
      "----------------------------------------\n",
      "\tfeature importance threshold: 0.05\n",
      "\tfeatures (5): form, don_form_trans_vol, one_time_trans_vol, amounts, min_amount\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.1299\n",
      "\t\tmse: 44720142.7527\n",
      "\tGBM:\n",
      "\t\tr2: 0.2656\n",
      "\t\tmse: 42469052.5087\n",
      "----------------------------------------\n",
      "\tfeature importance threshold: 0.1\n",
      "\tfeatures (3): form, don_form_trans_vol, min_amount\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.1704\n",
      "\t\tmse: 51281011.3848\n",
      "\tGBM:\n",
      "\t\tr2: 0.2689\n",
      "\t\tmse: 40769420.8744\n",
      "----------------------------------------\n",
      "\tfeature importance threshold: 0.15\n",
      "\tfeatures (2): form, min_amount\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.2285\n",
      "\t\tmse: 42995062.7410\n",
      "\tGBM:\n",
      "\t\tr2: 0.1414\n",
      "\t\tmse: 46684143.0534\n",
      "----------------------------------------\n",
      "count\n",
      "\tfeature importance threshold: 0.01\n",
      "\tfeatures (13): form, 11, 23, 27, 34, don_form_trans_count, kiosk_trans_count, mobile_trans_count, one_time_trans_count, rec_trans_vol, rec_trans_count, reg_count, month\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.6502\n",
      "\t\tmse: 375.3078\n",
      "\tGBM:\n",
      "\t\tr2: 0.5490\n",
      "\t\tmse: 481.2918\n",
      "----------------------------------------\n",
      "\tfeature importance threshold: 0.02\n",
      "\tfeatures (8): form, 23, 34, don_form_trans_count, one_time_trans_count, rec_trans_count, reg_count, month\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.6357\n",
      "\t\tmse: 385.2450\n",
      "\tGBM:\n",
      "\t\tr2: 0.5226\n",
      "\t\tmse: 503.4141\n",
      "----------------------------------------\n",
      "\tfeature importance threshold: 0.05\n",
      "\tfeatures (5): form, 23, don_form_trans_count, one_time_trans_count, month\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.6235\n",
      "\t\tmse: 408.6221\n",
      "\tGBM:\n",
      "\t\tr2: 0.5111\n",
      "\t\tmse: 504.4684\n",
      "----------------------------------------\n",
      "\tfeature importance threshold: 0.1\n",
      "\tfeatures (2): form, 23\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.5471\n",
      "\t\tmse: 474.1919\n",
      "\tGBM:\n",
      "\t\tr2: 0.3883\n",
      "\t\tmse: 645.7091\n",
      "----------------------------------------\n",
      "\tfeature importance threshold: 0.15\n",
      "\tfeatures (2): form, 23\n",
      "\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.5503\n",
      "\t\tmse: 470.8300\n",
      "\tGBM:\n",
      "\t\tr2: 0.3894\n",
      "\t\tmse: 651.0917\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for target in target_cols:\n",
    "    print(target)\n",
    "    \n",
    "    # model for feature importances\n",
    "    X_train = dataset.drop(target_cols, axis=1)\n",
    "    y_train = dataset[target]\n",
    "    \n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    feature_importances = []\n",
    "    for e in zip(X_train.columns, rf.feature_importances_):\n",
    "        feature_importances.append(e)\n",
    "    \n",
    "    for threshold in [0.01, 0.02, 0.05, 0.1, 0.15]:\n",
    "        print(\"\\tfeature importance threshold: {}\".format(threshold))\n",
    "        important_features = [c[0] for c in feature_importances if c[1] >= threshold]\n",
    "        print(\"\\tfeatures ({}): {}\".format(len(important_features), \", \".join([str(f) for f in important_features])))\n",
    "        print()\n",
    "        \n",
    "        # trial random forest model\n",
    "        scores = []\n",
    "        mses = []\n",
    "        for i in range(50):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(dataset[important_features], dataset[target])\n",
    "\n",
    "            rf = RandomForestRegressor()\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_test)\n",
    "\n",
    "            scores.append(rf.score(X_test, y_test))\n",
    "            mses.append(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        print(\"\\tRandom Forest:\")\n",
    "        print(\"\\t\\tr2: {:.4f}\".format(np.mean(scores)))\n",
    "        print(\"\\t\\tmse: {:.4f}\".format(np.mean(mses)))\n",
    "\n",
    "        # trial GBM model\n",
    "        scores = []\n",
    "        mses = []\n",
    "        for i in range(50):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(dataset[important_features], dataset[target])\n",
    "\n",
    "            gbm = GradientBoostingRegressor()\n",
    "            gbm.fit(X_train, y_train)\n",
    "            y_pred = gbm.predict(X_test)\n",
    "\n",
    "            scores.append(gbm.score(X_test, y_test))\n",
    "            mses.append(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        print(\"\\tGBM:\")\n",
    "        print(\"\\t\\tr2: {:.4f}\".format(np.mean(scores)))\n",
    "        print(\"\\t\\tmse: {:.4f}\".format(np.mean(mses)))\n",
    "\n",
    "        print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the feature importance filtering of feature sets used proves that this is not a fruitful direction. None of the models appear to significantly improve over the models with all available features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manual feature selection\n",
    "\n",
    "here we will manually pick fields to drop and/or model against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['vt_trans_count', 'don_form_trans_count', 'kiosk_trans_count',\n",
    "             'p2p_trans_count', 'mobile_trans_count', 'mobilevt_trans_count',\n",
    "             'sms_trans_count', 'fb_trans_count', 'vt_trans_vol',\n",
    "             'don_form_trans_vol', 'kiosk_trans_vol', 'p2p_trans_vol',\n",
    "             'mobile_trans_vol', 'mobilevt_trans_vol', 'sms_trans_vol',\n",
    "             'fb_trans_vol', 'one_time_trans_vol', 'one_time_trans_count',\n",
    "             'rec_trans_vol', 'rec_trans_count', 'pledges_count',\n",
    "             'dl_trans_volume', 'dl_trans_count', 'dl_new_rec_count', \n",
    "             'dl_new_rec_volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion_rate\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.0702\n",
      "\t\tmse: 10.2045\n",
      "\tGBM:\n",
      "\t\tr2: 0.0945\n",
      "\t\tmse: 9.8222\n",
      "----------------------------------------\n",
      "vol\n",
      "\tRandom Forest:\n",
      "\t\tr2: -0.1675\n",
      "\t\tmse: 61248839.1062\n",
      "\tGBM:\n",
      "\t\tr2: 0.1447\n",
      "\t\tmse: 54188345.5706\n",
      "----------------------------------------\n",
      "count\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.5589\n",
      "\t\tmse: 462.7969\n",
      "\tGBM:\n",
      "\t\tr2: 0.4450\n",
      "\t\tmse: 569.6800\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for target in target_cols:\n",
    "    print(target)\n",
    "    \n",
    "    scores = []\n",
    "    mses = []\n",
    "    for i in range(50):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dataset.drop(target_cols + drop_cols, axis=1), dataset[target])\n",
    "\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        \n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    print(\"\\tRandom Forest:\")\n",
    "    print(\"\\t\\tr2: {:.4f}\".format(np.mean(scores)))\n",
    "    print(\"\\t\\tmse: {:.4f}\".format(np.mean(mses)))\n",
    "    \n",
    "    scores = []\n",
    "    mses = []\n",
    "    for i in range(50):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dataset.drop(target_cols + drop_cols, axis=1), dataset[target])\n",
    "\n",
    "        gbm = GradientBoostingRegressor()\n",
    "        gbm.fit(X_train, y_train)\n",
    "        y_pred = gbm.predict(X_test)\n",
    "        \n",
    "        scores.append(gbm.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    print(\"\\tGBM:\")\n",
    "    print(\"\\t\\tr2: {:.4f}\".format(np.mean(scores)))\n",
    "    print(\"\\t\\tmse: {:.4f}\".format(np.mean(mses)))\n",
    "    \n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embeddings\n",
    "\n",
    "now we will introduce form embeddings modeled against the target variables (conversion rate, transaction volume, and transaction count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Flatten, Dense, Conv2D, BatchNormalization\n",
    "from keras import Sequential\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(features, target, dimensions):\n",
    "    X_train = np.array(features).reshape(len(features), 1)\n",
    "    \n",
    "    # create embedding model\n",
    "    mdl = Sequential()\n",
    "    mdl.add(Embedding(dim[0], dim[1], input_length=1))\n",
    "    mdl.add(Flatten())\n",
    "    mdl.add(Dense(1, activation='relu'))\n",
    "    mdl.compile('rmsprop', 'mse')\n",
    "    \n",
    "    # train embedding model\n",
    "    mdl.fit(X_train, target, epochs=10, batch_size=128, verbose=0)\n",
    "    \n",
    "    # return latent features\n",
    "    return mdl.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "embedding_lookup_table = {}\n",
    "\n",
    "unique_val_len = len(dataset['form'].unique())\n",
    "col_cat_values = dataset['form'].astype('category').cat.codes\n",
    "dataset['form'] = col_cat_values\n",
    "\n",
    "# define embedding\n",
    "dim = (unique_val_len, 30)\n",
    "\n",
    "for t in target_cols:\n",
    "    embedding_lookup_table[t] = generate_embedding(col_cat_values, dataset[t], dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion_rate\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.21823923620003863\n",
      "\t\tmse: 8.76016661250582\n",
      "\tGBM:\n",
      "\t\tr2: 0.23766000418331212\n",
      "\t\tmse: 8.336743066518471\n",
      "----------------------------------------\n",
      "vol\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.02881797956232817\n",
      "\t\tmse: 49014051.75955569\n",
      "\tGBM:\n",
      "\t\tr2: 0.26870094896470476\n",
      "\t\tmse: 44078988.19258527\n",
      "----------------------------------------\n",
      "count\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.6788153990386693\n",
      "\t\tmse: 339.39709611633555\n",
      "\tGBM:\n",
      "\t\tr2: 0.6721600821022655\n",
      "\t\tmse: 351.9316075671405\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for target in target_cols:\n",
    "    print(target)\n",
    "    # build dataset for the given target\n",
    "    #     continuous vars + embeddings for this target\n",
    "    target_col = dataset[target]\n",
    "    this_dataset = dataset.drop(target_cols + drop_cols, axis=1).copy()\n",
    "    \n",
    "    # set new feature columns for embeddings mapped to the categorical values    \n",
    "    for new_col_i in range(embedding_lookup_table[target].shape[1]):\n",
    "        new_col_label = \"_\".join([\"form\", str(new_col_i)])\n",
    "        this_dataset[new_col_label] = this_dataset[\"form\"].apply(lambda x: embedding_lookup_table[target][x][new_col_i])\n",
    "    \n",
    "    # train & evaluate\n",
    "    scores = []\n",
    "    mses = []\n",
    "    for i in range(50):\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset, target_col)\n",
    "        \n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        \n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\tRandom Forest:\")\n",
    "    print(\"\\t\\tr2: {}\".format(np.mean(scores)))\n",
    "    print(\"\\t\\tmse: {}\".format(np.mean(mses)))\n",
    "    \n",
    "    scores = []\n",
    "    mses = []\n",
    "    for i in range(50):\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset, target_col)\n",
    "        \n",
    "        gbm = GradientBoostingRegressor()\n",
    "        gbm.fit(X_train, y_train)\n",
    "        y_pred = gbm.predict(X_test)\n",
    "        \n",
    "        scores.append(gbm.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    print(\"\\tGBM:\")\n",
    "    print(\"\\t\\tr2: {}\".format(np.mean(scores)))\n",
    "    print(\"\\t\\tmse: {}\".format(np.mean(mses)))  \n",
    "    \n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the performance here is not substantially improved over the previous models. let's try dropping the logs features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['vt_trans_count', 'don_form_trans_count', 'kiosk_trans_count',\n",
    "             'p2p_trans_count', 'mobile_trans_count', 'mobilevt_trans_count',\n",
    "             'sms_trans_count', 'fb_trans_count', 'vt_trans_vol',\n",
    "             'don_form_trans_vol', 'kiosk_trans_vol', 'p2p_trans_vol',\n",
    "             'mobile_trans_vol', 'mobilevt_trans_vol', 'sms_trans_vol',\n",
    "             'fb_trans_vol', 'one_time_trans_vol', 'one_time_trans_count',\n",
    "             'rec_trans_vol', 'rec_trans_count', 'pledges_count',\n",
    "             'dl_trans_volume', 'dl_trans_count', 'dl_new_rec_count', \n",
    "             'dl_new_rec_volume', 0, 4, 8, 11, 12, 13, 15, 18, 20, 21, 23, 24, 25, \n",
    "             26, 27, 28, 29, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion_rate\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.20727948639712246\n",
      "\t\tmse: 9.036881787617105\n",
      "\tGBM:\n",
      "\t\tr2: 0.2686532193955593\n",
      "\t\tmse: 7.734312131069073\n",
      "----------------------------------------\n",
      "vol\n",
      "\tRandom Forest:\n",
      "\t\tr2: -0.06297748334943935\n",
      "\t\tmse: 49806526.6833537\n",
      "\tGBM:\n",
      "\t\tr2: 0.2916495413296447\n",
      "\t\tmse: 32806750.993362583\n",
      "----------------------------------------\n",
      "count\n",
      "\tRandom Forest:\n",
      "\t\tr2: 0.6551663792320632\n",
      "\t\tmse: 363.5063640817677\n",
      "\tGBM:\n",
      "\t\tr2: 0.6519776456726603\n",
      "\t\tmse: 366.1795924394368\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for target in target_cols:\n",
    "    print(target)\n",
    "    # build dataset for the given target\n",
    "    #     continuous vars + embeddings for this target\n",
    "    target_col = dataset[target]\n",
    "    this_dataset = dataset.drop(target_cols + drop_cols, axis=1).copy()\n",
    "    \n",
    "    # set new feature columns for embeddings mapped to the categorical values    \n",
    "    for new_col_i in range(embedding_lookup_table[target].shape[1]):\n",
    "        new_col_label = \"_\".join([\"form\", str(new_col_i)])\n",
    "        this_dataset[new_col_label] = this_dataset[\"form\"].apply(lambda x: embedding_lookup_table[target][x][new_col_i])\n",
    "    \n",
    "    # train & evaluate\n",
    "    scores = []\n",
    "    mses = []\n",
    "    for i in range(50):\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset, target_col)\n",
    "        \n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        \n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\tRandom Forest:\")\n",
    "    print(\"\\t\\tr2: {}\".format(np.mean(scores)))\n",
    "    print(\"\\t\\tmse: {}\".format(np.mean(mses)))\n",
    "    \n",
    "    scores = []\n",
    "    mses = []\n",
    "    for i in range(50):\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset, target_col)\n",
    "        \n",
    "        gbm = GradientBoostingRegressor()\n",
    "        gbm.fit(X_train, y_train)\n",
    "        y_pred = gbm.predict(X_test)\n",
    "        \n",
    "        scores.append(gbm.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    print(\"\\tGBM:\")\n",
    "    print(\"\\t\\tr2: {}\".format(np.mean(scores)))\n",
    "    print(\"\\t\\tmse: {}\".format(np.mean(mses)))  \n",
    "    \n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('form', 0.08628994719767717),\n",
       " ('events_priv_count', 4.666898261872729e-06),\n",
       " ('restrictions', 0.010414916090877895),\n",
       " ('amounts', 0.012806514643285954),\n",
       " ('ded_types', 0.0020796072964005346),\n",
       " ('opt_ded_flds', 0.0),\n",
       " ('req_ded_flds', 7.366160513063452e-05),\n",
       " ('opt_fields', 0.0015442082310413133),\n",
       " ('req_fields', 0.004165856382411219),\n",
       " ('pledge_active', 0.00042981510693742913),\n",
       " ('donation_active', 0.01164288647357134),\n",
       " ('multirestriction_system', 0.0012775614798510118),\n",
       " ('min_amount', 0.0006971784946854471),\n",
       " ('max_amount', 0.009107610261678976),\n",
       " ('permit_anonymous', 0.0005113841947945359),\n",
       " ('permit_recurring', 0.0),\n",
       " ('permit_other_amount', 0.007195401904719066),\n",
       " ('permit_create_own_pledge', 0.0022013709370277985),\n",
       " ('collect_company', 0.002955845434927846),\n",
       " ('collect_phone', 0.006170031094036755),\n",
       " ('collect_optin', 0.002321045754145229),\n",
       " ('collect_captcha', 0.0),\n",
       " ('collect_address_mobile', 0.0004634057427972193),\n",
       " ('enable_donorlogins', 0.003301904225400547),\n",
       " ('enable_sms', 0.0006015361152211419),\n",
       " ('new_rec_volume', 0.07022736041746372),\n",
       " ('new_rec_count', 0.09096779306944207),\n",
       " ('reg_count', 0.02711302315870736),\n",
       " ('month', 0.20552439360791191),\n",
       " ('form_0', 0.006897983226092664),\n",
       " ('form_1', 0.004154486073444071),\n",
       " ('form_2', 0.008077306883324675),\n",
       " ('form_3', 0.040529135764156184),\n",
       " ('form_4', 0.02800358684326403),\n",
       " ('form_5', 0.006339669882895728),\n",
       " ('form_6', 0.007788015716315537),\n",
       " ('form_7', 0.03604806434086162),\n",
       " ('form_8', 0.008156953940438237),\n",
       " ('form_9', 0.005477207845554713),\n",
       " ('form_10', 0.011453121494935537),\n",
       " ('form_11', 0.011022992899634284),\n",
       " ('form_12', 0.006813820598413725),\n",
       " ('form_13', 0.012512985663332707),\n",
       " ('form_14', 0.007820160920077616),\n",
       " ('form_15', 0.0405916820056924),\n",
       " ('form_16', 0.009690904146012713),\n",
       " ('form_17', 0.011886547905133663),\n",
       " ('form_18', 0.012153581883642416),\n",
       " ('form_19', 0.014069636826505656),\n",
       " ('form_20', 0.0025486360042601052),\n",
       " ('form_21', 0.023472837808812798),\n",
       " ('form_22', 0.005475780137545705),\n",
       " ('form_23', 0.012132969332870055),\n",
       " ('form_24', 0.021055202786114183),\n",
       " ('form_25', 0.057464962351233176),\n",
       " ('form_26', 0.008212068730656061),\n",
       " ('form_27', 0.005283083974612237),\n",
       " ('form_28', 0.006059130148135377),\n",
       " ('form_29', 0.008718558047626206)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col = dataset['conversion_rate']\n",
    "X_train, X_test, y_train, y_test = train_test_split(this_dataset, target_col)\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = []\n",
    "for e in zip(X_train.columns, rf.feature_importances_):\n",
    "    feature_importances.append(e)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
