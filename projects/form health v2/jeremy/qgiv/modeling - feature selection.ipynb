{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../../scripts/\")\n",
    "from s3_support import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to model on everything conceivably relevant and use random forest regressor to select important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''select\n",
    "            date_trunc('week', date) as week,\n",
    "            org,\n",
    "            form,\n",
    "            sum(views) as pageviews\n",
    "        from googleanalytics_traffic\n",
    "            where date >= 2016 and date <= 2019\n",
    "        group by date_trunc('week', date), org, form;'''\n",
    "pageviews = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageviews = pageviews[pageviews['form']!=0]\n",
    "pageviews.sort_values('week', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load transaction growth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''select \n",
    "            form, \n",
    "            date_trunc('week', date) as week,\n",
    "            count(id) as count, \n",
    "            sum(amount) as vol\n",
    "        from transactions\n",
    "        where status='A' and date>=2016 and date<=2019\n",
    "        group by form, date_trunc('week', date)\n",
    "    '''\n",
    "trans = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256129, 11558)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans), len(trans['form'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['week'] = pd.to_datetime(trans['week'])\n",
    "trans.sort_values('week', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge traffic and transactions\n",
    "trans = trans.merge(pageviews, on=['form', 'week'])\n",
    "\n",
    "# calculate conversion rate & change\n",
    "trans['conversion_rate'] = trans['count'] / trans['pageviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>week</th>\n",
       "      <th>count</th>\n",
       "      <th>vol</th>\n",
       "      <th>org</th>\n",
       "      <th>pageviews</th>\n",
       "      <th>conversion_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1849</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>1</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1793</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16414</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2994</td>\n",
       "      <td>26</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>842872</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>430121</td>\n",
       "      <td>12</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     form       week  count    vol     org  pageviews  conversion_rate\n",
       "0    1849 2017-02-06      1   84.0    1793          9         0.111111\n",
       "1   16414 2017-02-06      1    0.0    2994         26         0.038462\n",
       "2  842872 2017-02-06      1  100.0  430121         12         0.083333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118784, 2592)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form_data = None\n",
    "\n",
    "for form in trans['form'].unique():\n",
    "    if form == 0:\n",
    "        continue\n",
    "    this_df = trans[trans['form']==form].copy()\n",
    "    if len(this_df) >= 12:\n",
    "        this_df['count_growth'] = this_df['count'].pct_change()\n",
    "        this_df['vol_growth'] = this_df['vol'].pct_change()\n",
    "        this_df['conversion_growth'] = this_df['conversion_rate'].pct_change()\n",
    "\n",
    "        if form_data is None:\n",
    "            form_data = this_df\n",
    "        else:\n",
    "            form_data = form_data.append(this_df)\n",
    "len(form_data), len(form_data['form'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''select\n",
    "            form,\n",
    "            date_trunc('week', created) as week,\n",
    "            systemtype,\n",
    "            count(id) as count\n",
    "        from logs\n",
    "        where created>=2016 and created <=2019 and form!=0\n",
    "        group by form, systemtype, date_trunc('week', created)'''\n",
    "logs = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161595, 20563)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs), len(logs['form'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>systemtype</th>\n",
       "      <th>form</th>\n",
       "      <th>week</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "systemtype  form       week    0    4    8   11   12   13   15   18 ...    34  \\\n",
       "0              1 2016-05-02  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0 ...   0.0   \n",
       "1              1 2016-05-30  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0 ...   0.0   \n",
       "2              1 2016-06-20  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0 ...   0.0   \n",
       "3              1 2016-06-27  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0 ...   0.0   \n",
       "4              1 2016-07-04  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0 ...   0.0   \n",
       "\n",
       "systemtype   35   36   38   39   40   41   42   43   44  \n",
       "0           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4           0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_pvt = pd.pivot_table(logs, index=['form', 'week'], columns='systemtype', values='count').reset_index()\n",
    "logs_pvt.fillna(0, inplace=True)\n",
    "logs_pvt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>week</th>\n",
       "      <th>form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    4    8   11   12   13   15   18   20   21  ...    36   38   39   40  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "    41   42   43   44       week  form  \n",
       "0  0.0  0.0  0.0  0.0 2016-05-02     1  \n",
       "1  0.0  0.0  0.0  0.0 2016-05-30     1  \n",
       "2  0.0  0.0  0.0  0.0 2016-06-20     1  \n",
       "3  0.0  0.0  0.0  0.0 2016-06-27     1  \n",
       "4  0.0  0.0  0.0  0.0 2016-07-04     1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxd_month = logs_pvt['week']\n",
    "idxd_form = logs_pvt['form']\n",
    "logs_pct_change = logs_pvt.drop('week', axis=1).groupby('form').pct_change()\n",
    "logs_pct_change['week'] = idxd_month\n",
    "logs_pct_change['form'] = idxd_form\n",
    "logs_pct_change = logs_pct_change.fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "logs_pct_change.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"select * from analytics_weekly\"\n",
    "df_base = redshift_query_read(q)\n",
    "q = \"select * from analyticsqgiv_weekly\"\n",
    "df_qgiv = redshift_query_read(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 86)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_base['date'].unique()), len(df_qgiv['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analytics = df_base.merge(df_qgiv, on=[\"org\", \"form\", \"date\"]).dropna()\n",
    "\n",
    "df_analytics = df_analytics.drop(['org', 'product'], axis=1).groupby(['date', 'form']).sum().reset_index()\n",
    "df_analytics['date'] = pd.to_datetime(df_analytics['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1189306, 23750, 86)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_analytics), len(df_analytics['form'].unique()), len(df_analytics['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_analytics = None\n",
    "for form in df_analytics['form'].unique():\n",
    "    this_df = df_analytics[df_analytics['form']==form].copy()\n",
    "    this_df['week'] = this_df['date']\n",
    "\n",
    "    for c in this_df.columns:\n",
    "        if c not in ['date', 'form', 'week']:\n",
    "            this_df[\"{}_pct_change\".format(c)] = this_df[c].pct_change()\n",
    "            \n",
    "    ext_cols = ['form', 'week'] + [c for c in this_df.columns if '_pct_change' in c]\n",
    "    \n",
    "    if agg_analytics is None:\n",
    "        agg_analytics = this_df[ext_cols]\n",
    "    else:\n",
    "        agg_analytics = agg_analytics.append(this_df[ext_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>week</th>\n",
       "      <th>vt_trans_count_pct_change</th>\n",
       "      <th>don_form_trans_count_pct_change</th>\n",
       "      <th>kiosk_trans_count_pct_change</th>\n",
       "      <th>p2p_trans_count_pct_change</th>\n",
       "      <th>mobile_trans_count_pct_change</th>\n",
       "      <th>mobilevt_trans_count_pct_change</th>\n",
       "      <th>sms_trans_count_pct_change</th>\n",
       "      <th>fb_trans_count_pct_change</th>\n",
       "      <th>...</th>\n",
       "      <th>collect_address_mobile_pct_change</th>\n",
       "      <th>enable_donorlogins_pct_change</th>\n",
       "      <th>enable_sms_pct_change</th>\n",
       "      <th>new_rec_volume_pct_change</th>\n",
       "      <th>new_rec_count_pct_change</th>\n",
       "      <th>reg_count_pct_change</th>\n",
       "      <th>dl_trans_volume_pct_change</th>\n",
       "      <th>dl_trans_count_pct_change</th>\n",
       "      <th>dl_new_rec_count_pct_change</th>\n",
       "      <th>dl_new_rec_volume_pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5534</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11106</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>8.081803</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17186</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-29</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.368421</td>\n",
       "      <td>-0.801471</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23295</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-05</td>\n",
       "      <td>-0.354167</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.488889</td>\n",
       "      <td>-0.796296</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       form       week  vt_trans_count_pct_change  \\\n",
       "0         1 2017-05-08                   0.000000   \n",
       "5534      1 2017-05-15                 100.000000   \n",
       "11106     1 2017-05-22                   1.777778   \n",
       "17186     1 2017-05-29                   0.920000   \n",
       "23295     1 2017-06-05                  -0.354167   \n",
       "\n",
       "       don_form_trans_count_pct_change  kiosk_trans_count_pct_change  \\\n",
       "0                             0.000000                           0.0   \n",
       "5534                        100.000000                           0.0   \n",
       "11106                         4.500000                           0.0   \n",
       "17186                        -0.454545                           0.0   \n",
       "23295                         2.166667                           0.0   \n",
       "\n",
       "       p2p_trans_count_pct_change  mobile_trans_count_pct_change  \\\n",
       "0                             0.0                       0.000000   \n",
       "5534                          0.0                     100.000000   \n",
       "11106                         0.0                       3.000000   \n",
       "17186                         0.0                       0.500000   \n",
       "23295                         0.0                      -0.833333   \n",
       "\n",
       "       mobilevt_trans_count_pct_change  sms_trans_count_pct_change  \\\n",
       "0                                  0.0                         0.0   \n",
       "5534                               0.0                         0.0   \n",
       "11106                              0.0                         0.0   \n",
       "17186                              0.0                         0.0   \n",
       "23295                              0.0                         0.0   \n",
       "\n",
       "       fb_trans_count_pct_change              ...               \\\n",
       "0                            0.0              ...                \n",
       "5534                         0.0              ...                \n",
       "11106                        0.0              ...                \n",
       "17186                        0.0              ...                \n",
       "23295                        0.0              ...                \n",
       "\n",
       "       collect_address_mobile_pct_change  enable_donorlogins_pct_change  \\\n",
       "0                                    0.0                            0.0   \n",
       "5534                                 0.0                            0.0   \n",
       "11106                                0.0                           -1.0   \n",
       "17186                                0.0                            0.0   \n",
       "23295                                0.0                            0.0   \n",
       "\n",
       "       enable_sms_pct_change  new_rec_volume_pct_change  \\\n",
       "0                        0.0                        0.0   \n",
       "5534                     0.0                        0.0   \n",
       "11106                    0.0                      100.0   \n",
       "17186                    0.0                       -1.0   \n",
       "23295                    0.0                      100.0   \n",
       "\n",
       "       new_rec_count_pct_change  reg_count_pct_change  \\\n",
       "0                           0.0              0.000000   \n",
       "5534                        0.0            100.000000   \n",
       "11106                     100.0              5.333333   \n",
       "17186                      -1.0              1.368421   \n",
       "23295                     100.0             -0.488889   \n",
       "\n",
       "       dl_trans_volume_pct_change  dl_trans_count_pct_change  \\\n",
       "0                        0.000000                   0.000000   \n",
       "5534                   100.000000                 100.000000   \n",
       "11106                    8.081803                  11.000000   \n",
       "17186                   -0.801471                  -0.666667   \n",
       "23295                   -0.796296                  -0.750000   \n",
       "\n",
       "       dl_new_rec_count_pct_change  dl_new_rec_volume_pct_change  \n",
       "0                              0.0                           0.0  \n",
       "5534                           0.0                           0.0  \n",
       "11106                          0.0                           0.0  \n",
       "17186                          0.0                           0.0  \n",
       "23295                        100.0                         100.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_analytics = agg_analytics.fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "agg_analytics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1189306, 86, 23750)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agg_analytics), len(agg_analytics['week'].unique()), len(agg_analytics['form'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data set\n",
    "dataset = form_data.dropna()[['form', 'week', 'count_growth', 'vol_growth', 'conversion_rate', 'conversion_growth']]\n",
    "dataset = dataset.merge(logs_pct_change, on=['form', 'week'])\n",
    "dataset = dataset.merge(agg_analytics, on=['form', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7031, 1291, 39)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), len(dataset['form'].unique()), len(dataset['week'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['month_cat'] = dataset['week'].dt.month\n",
    "\n",
    "target_cols = ['count_growth', 'vol_growth', 'vt_trans_count_pct_change', \n",
    "               'don_form_trans_count_pct_change', 'kiosk_trans_count_pct_change', \n",
    "               'p2p_trans_count_pct_change', 'mobile_trans_count_pct_change', \n",
    "               'mobilevt_trans_count_pct_change', 'sms_trans_count_pct_change', \n",
    "               'fb_trans_count_pct_change', 'vt_trans_vol_pct_change', \n",
    "               'don_form_trans_vol_pct_change', 'kiosk_trans_vol_pct_change', \n",
    "               'p2p_trans_vol_pct_change', 'mobile_trans_vol_pct_change', \n",
    "               'mobilevt_trans_vol_pct_change', 'sms_trans_vol_pct_change', \n",
    "               'fb_trans_vol_pct_change', 'one_time_trans_vol_pct_change', \n",
    "               'one_time_trans_count_pct_change', 'rec_trans_vol_pct_change', \n",
    "               'rec_trans_count_pct_change', 'new_rec_volume_pct_change', \n",
    "               'new_rec_count_pct_change', 'reg_count_pct_change', \n",
    "               'dl_trans_volume_pct_change', 'dl_trans_count_pct_change', \n",
    "               'dl_new_rec_count_pct_change', 'dl_new_rec_volume_pct_change',\n",
    "               'conversion_rate', 'conversion_growth']\n",
    "\n",
    "feature_cols = [c for c in dataset.columns if c not in target_cols and c != 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_growth\n",
      "-0.5271733914176864\n",
      "----------------------------------------\n",
      "vol_growth\n",
      "-1.666188140949322\n",
      "----------------------------------------\n",
      "vt_trans_count_pct_change\n",
      "-0.22440504992914817\n",
      "----------------------------------------\n",
      "don_form_trans_count_pct_change\n",
      "-0.13357885673147699\n",
      "----------------------------------------\n",
      "kiosk_trans_count_pct_change\n",
      "-0.1753934993953516\n",
      "----------------------------------------\n",
      "p2p_trans_count_pct_change\n",
      "1.0\n",
      "----------------------------------------\n",
      "mobile_trans_count_pct_change\n",
      "-0.24969752555534286\n",
      "----------------------------------------\n",
      "mobilevt_trans_count_pct_change\n",
      "-0.4091664699098265\n",
      "----------------------------------------\n",
      "sms_trans_count_pct_change\n",
      "-0.23329877055533316\n",
      "----------------------------------------\n",
      "fb_trans_count_pct_change\n",
      "-0.3300465762810979\n",
      "----------------------------------------\n",
      "vt_trans_vol_pct_change\n",
      "-0.22998106933385762\n",
      "----------------------------------------\n",
      "don_form_trans_vol_pct_change\n",
      "-0.10390985366877067\n",
      "----------------------------------------\n",
      "kiosk_trans_vol_pct_change\n",
      "-3.9626925701416225\n",
      "----------------------------------------\n",
      "p2p_trans_vol_pct_change\n",
      "1.0\n",
      "----------------------------------------\n",
      "mobile_trans_vol_pct_change\n",
      "-0.4228073526301828\n",
      "----------------------------------------\n",
      "mobilevt_trans_vol_pct_change\n",
      "-0.5549291393021963\n",
      "----------------------------------------\n",
      "sms_trans_vol_pct_change\n",
      "-1.362677303493895\n",
      "----------------------------------------\n",
      "fb_trans_vol_pct_change\n",
      "-0.16342952252403953\n",
      "----------------------------------------\n",
      "one_time_trans_vol_pct_change\n",
      "-0.13587651600985612\n",
      "----------------------------------------\n",
      "one_time_trans_count_pct_change\n",
      "-0.14807034907484323\n",
      "----------------------------------------\n",
      "rec_trans_vol_pct_change\n",
      "-0.14873117758046844\n",
      "----------------------------------------\n",
      "rec_trans_count_pct_change\n",
      "-0.16981523040127897\n",
      "----------------------------------------\n",
      "new_rec_volume_pct_change\n",
      "-0.17902846662824992\n",
      "----------------------------------------\n",
      "new_rec_count_pct_change\n",
      "-0.1603513590205682\n",
      "----------------------------------------\n",
      "reg_count_pct_change\n",
      "-0.22915273444459022\n",
      "----------------------------------------\n",
      "dl_trans_volume_pct_change\n",
      "-0.21081909771789223\n",
      "----------------------------------------\n",
      "dl_trans_count_pct_change\n",
      "-0.14948854551751284\n",
      "----------------------------------------\n",
      "dl_new_rec_count_pct_change\n",
      "-0.1857646658132402\n",
      "----------------------------------------\n",
      "dl_new_rec_volume_pct_change\n",
      "-0.1676018357087506\n",
      "----------------------------------------\n",
      "conversion_rate\n",
      "-0.14107707840442307\n",
      "----------------------------------------\n",
      "conversion_growth\n",
      "-1.028891535479884\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for target in target_cols:\n",
    "    scores = []\n",
    "    for i in range(10):\n",
    "        # build training data set\n",
    "        feature_cols = [c for c in dataset.columns if c not in target_cols + ['week', 'form']]\n",
    "        this_dataset = dataset[feature_cols + [target]].fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset.drop(target, axis=1), this_dataset[target])\n",
    "\n",
    "        # fit & evaluate\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "    \n",
    "    print(target)\n",
    "    print(np.mean(scores))\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -0.2409\n",
      "MSE: 27.7901\n"
     ]
    }
   ],
   "source": [
    "target = 'conversion_rate'\n",
    "# build training data set\n",
    "feature_cols = [c for c in dataset.columns if c not in target_cols + ['week', 'form']]\n",
    "this_dataset = dataset[feature_cols + [target]].fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(this_dataset.drop(target, axis=1), this_dataset[target])\n",
    "\n",
    "# fit & evaluate\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "score = rf.score(X_test, y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Score: {:.4f}\".format(score))\n",
    "print(\"MSE: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23, 0.46165781559366276),\n",
       " (34, 0.27147130423714994),\n",
       " ('month_cat', 0.16718135920046273),\n",
       " (15, 0.0679959041853855),\n",
       " (11, 0.010728607293287801),\n",
       " ('restrictions_pct_change', 0.005859539997873421),\n",
       " (21, 0.0039453657215477705),\n",
       " (24, 0.0033608831249170926),\n",
       " (32, 0.002250226669552224),\n",
       " (29, 0.0016749183805165491),\n",
       " ('amounts_pct_change', 0.0008804325266941951),\n",
       " (36, 0.000715724873861379),\n",
       " (35, 0.0005578935457734992),\n",
       " ('max_amount_pct_change', 0.00042154034010384166),\n",
       " ('req_fields_pct_change', 0.0003425451438763546),\n",
       " ('collect_optin_pct_change', 0.00015902283879378243),\n",
       " ('permit_anonymous_pct_change', 0.0001465168660196595),\n",
       " ('donation_active_pct_change', 0.00010854831786132563),\n",
       " ('opt_fields_pct_change', 7.183126763265795e-05),\n",
       " ('pledge_active_pct_change', 6.484622694400228e-05)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = []\n",
    "for e in zip(X_train.columns, rf.feature_importances_):\n",
    "    feature_importances.append(e)\n",
    "sorted(feature_importances, key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance threshold: 1.00%\n",
      "\tscore: -0.1488\n",
      "\tmse: 36.5524\n",
      "\tfeature count: 5\n",
      "Feature importance threshold: 2.00%\n",
      "\tscore: -0.1514\n",
      "\tmse: 35.7776\n",
      "\tfeature count: 4\n",
      "Feature importance threshold: 5.00%\n",
      "\tscore: -0.1145\n",
      "\tmse: 34.8520\n",
      "\tfeature count: 4\n",
      "Feature importance threshold: 10.00%\n",
      "\tscore: -0.1932\n",
      "\tmse: 36.7331\n",
      "\tfeature count: 3\n",
      "Feature importance threshold: 15.00%\n",
      "\tscore: -0.1851\n",
      "\tmse: 37.8118\n",
      "\tfeature count: 3\n"
     ]
    }
   ],
   "source": [
    "for threshold in [0.01, 0.02, 0.05, 0.1, 0.15]:\n",
    "    scores = []\n",
    "    mses = []\n",
    "    \n",
    "    for i in range(50):\n",
    "        # features with importances greater than 1%\n",
    "        features_gt_one = [c[0] for c in feature_importances if c[1] >= threshold]\n",
    "        target = 'conversion_rate'\n",
    "\n",
    "        # build training data set\n",
    "        feature_cols = features_gt_one\n",
    "        this_dataset = dataset[feature_cols + [target]].fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset.drop(target, axis=1), this_dataset[target])\n",
    "\n",
    "        # fit & evaluate\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = rf.predict(X_test)\n",
    "\n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    print(\"Feature importance threshold: {:.2f}%\".format(threshold * 100.))\n",
    "    print(\"\\tscore: {:.4f}\".format(np.mean(scores)))\n",
    "    print(\"\\tmse: {:.4f}\".format(np.mean(mses)))\n",
    "    print(\"\\tfeature count: {}\".format(len(features_gt_one)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversion_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -0.2054\n",
      "MSE: 70.8439\n"
     ]
    }
   ],
   "source": [
    "target = 'conversion_growth'\n",
    "# build training data set\n",
    "feature_cols = [c for c in dataset.columns if c not in target_cols + ['week', 'form']]\n",
    "this_dataset = dataset[feature_cols + [target]].fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(this_dataset.drop(target, axis=1), this_dataset[target])\n",
    "\n",
    "# fit & evaluate\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "score = rf.score(X_test, y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Score: {:.4f}\".format(score))\n",
    "print(\"MSE: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(34, 0.42831441761252337),\n",
       " ('month_cat', 0.2666081387538331),\n",
       " (23, 0.15892488743632777),\n",
       " ('restrictions_pct_change', 0.031183908349918705),\n",
       " (11, 0.026156784179357868),\n",
       " ('multirestriction_system_pct_change', 0.014538548381268552),\n",
       " (24, 0.010467188585861932),\n",
       " (44, 0.007223573408846261),\n",
       " (21, 0.00704278517880986),\n",
       " ('collect_company_pct_change', 0.006971753637867335),\n",
       " ('amounts_pct_change', 0.006644023948236921),\n",
       " (15, 0.004740124294218902),\n",
       " (29, 0.004239275977218146),\n",
       " (32, 0.0038086178838063847),\n",
       " ('opt_fields_pct_change', 0.0032208351403693763),\n",
       " (35, 0.002691012713422169),\n",
       " ('collect_optin_pct_change', 0.002334469469790274),\n",
       " ('min_amount_pct_change', 0.002026455532645311),\n",
       " (36, 0.0016449823980282368),\n",
       " ('collect_phone_pct_change', 0.0015681450358530139)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = []\n",
    "for e in zip(X_train.columns, rf.feature_importances_):\n",
    "    feature_importances.append(e)\n",
    "sorted(feature_importances, key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance threshold: 1.00%\n",
      "\tscore: -0.6335\n",
      "\tmse: 36.4306\n",
      "\tfeature count: 7\n",
      "Feature importance threshold: 2.00%\n",
      "\tscore: -0.5404\n",
      "\tmse: 46.9653\n",
      "\tfeature count: 5\n",
      "Feature importance threshold: 5.00%\n",
      "\tscore: -0.7527\n",
      "\tmse: 42.6595\n",
      "\tfeature count: 3\n",
      "Feature importance threshold: 10.00%\n",
      "\tscore: -0.5147\n",
      "\tmse: 45.4989\n",
      "\tfeature count: 3\n",
      "Feature importance threshold: 15.00%\n",
      "\tscore: -0.5416\n",
      "\tmse: 48.2491\n",
      "\tfeature count: 3\n"
     ]
    }
   ],
   "source": [
    "for threshold in [0.01, 0.02, 0.05, 0.1, 0.15]:\n",
    "    scores = []\n",
    "    mses = []\n",
    "    \n",
    "    for i in range(50):\n",
    "        # features with importances greater than 1%\n",
    "        features_gt_one = [c[0] for c in feature_importances if c[1] >= threshold]\n",
    "        target = 'conversion_growth'\n",
    "\n",
    "        # build training data set\n",
    "        feature_cols = features_gt_one\n",
    "        this_dataset = dataset[feature_cols + [target]].fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset.drop(target, axis=1), this_dataset[target])\n",
    "\n",
    "        # fit & evaluate\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = rf.predict(X_test)\n",
    "\n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    print(\"Feature importance threshold: {:.2f}%\".format(threshold * 100.))\n",
    "    print(\"\\tscore: {:.4f}\".format(np.mean(scores)))\n",
    "    print(\"\\tmse: {:.4f}\".format(np.mean(mses)))\n",
    "    print(\"\\tfeature count: {}\".format(len(features_gt_one)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## don_form_trans_count_pct_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -0.1284\n",
      "MSE: 1135.3879\n"
     ]
    }
   ],
   "source": [
    "target = 'don_form_trans_count_pct_change'\n",
    "# build training data set\n",
    "feature_cols = [c for c in dataset.columns if c not in target_cols + ['week', 'form']]\n",
    "this_dataset = dataset[feature_cols + [target]].fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(this_dataset.drop(target, axis=1), this_dataset[target])\n",
    "\n",
    "# fit & evaluate\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "score = rf.score(X_test, y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Score: {:.4f}\".format(score))\n",
    "print(\"MSE: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('month_cat', 0.1812163739155677),\n",
       " (23, 0.17094495239755125),\n",
       " (11, 0.15526687132749883),\n",
       " (34, 0.12621455387209926),\n",
       " ('restrictions_pct_change', 0.043091032914588594),\n",
       " (29, 0.03889496880387942),\n",
       " (21, 0.033783780346431966),\n",
       " (32, 0.03307026931154995),\n",
       " ('amounts_pct_change', 0.028825289329625338),\n",
       " (24, 0.027671950225588503),\n",
       " (36, 0.020452654635550842),\n",
       " ('collect_optin_pct_change', 0.014905976285460218),\n",
       " (15, 0.01416558824065842),\n",
       " ('min_amount_pct_change', 0.010217464085216638),\n",
       " ('opt_fields_pct_change', 0.00907240263245777),\n",
       " ('pledge_active_pct_change', 0.00794943329263253),\n",
       " ('enable_sms_pct_change', 0.007052312612578569),\n",
       " ('req_fields_pct_change', 0.006983309550379626),\n",
       " ('collect_phone_pct_change', 0.006758852344338385),\n",
       " ('pledges_count_pct_change', 0.006296840521217187)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = []\n",
    "for e in zip(X_train.columns, rf.feature_importances_):\n",
    "    feature_importances.append(e)\n",
    "sorted(feature_importances, key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance threshold: 1.00%\n",
      "\tscore: -0.1564\n",
      "\tmse: 1250.9058\n",
      "\tfeature count: 14\n",
      "Feature importance threshold: 2.00%\n",
      "\tscore: -0.1506\n",
      "\tmse: 1237.1203\n",
      "\tfeature count: 11\n",
      "Feature importance threshold: 5.00%\n",
      "\tscore: -0.0968\n",
      "\tmse: 1205.1127\n",
      "\tfeature count: 4\n",
      "Feature importance threshold: 10.00%\n",
      "\tscore: -0.0997\n",
      "\tmse: 1171.0008\n",
      "\tfeature count: 4\n",
      "Feature importance threshold: 15.00%\n",
      "\tscore: -0.0557\n",
      "\tmse: 1139.7518\n",
      "\tfeature count: 3\n"
     ]
    }
   ],
   "source": [
    "for threshold in [0.01, 0.02, 0.05, 0.1, 0.15]:\n",
    "    scores = []\n",
    "    mses = []\n",
    "    \n",
    "    for i in range(50):\n",
    "        # features with importances greater than 1%\n",
    "        features_gt_one = [c[0] for c in feature_importances if c[1] >= threshold]\n",
    "        target = 'don_form_trans_count_pct_change'\n",
    "\n",
    "        # build training data set\n",
    "        feature_cols = features_gt_one\n",
    "        this_dataset = dataset[feature_cols + [target]].fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset.drop(target, axis=1), this_dataset[target])\n",
    "\n",
    "        # fit & evaluate\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = rf.predict(X_test)\n",
    "\n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    print(\"Feature importance threshold: {:.2f}%\".format(threshold * 100.))\n",
    "    print(\"\\tscore: {:.4f}\".format(np.mean(scores)))\n",
    "    print(\"\\tmse: {:.4f}\".format(np.mean(mses)))\n",
    "    print(\"\\tfeature count: {}\".format(len(features_gt_one)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new_rec_count_pct_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -0.1845\n",
      "MSE: 1341.9832\n"
     ]
    }
   ],
   "source": [
    "target = 'new_rec_count_pct_change'\n",
    "# build training data set\n",
    "feature_cols = [c for c in dataset.columns if c not in target_cols + ['week', 'form']]\n",
    "this_dataset = dataset[feature_cols + [target]].fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(this_dataset.drop(target, axis=1), this_dataset[target])\n",
    "\n",
    "# fit & evaluate\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "score = rf.score(X_test, y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Score: {:.4f}\".format(score))\n",
    "print(\"MSE: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23, 0.21518587523111044),\n",
       " (11, 0.19339405583988442),\n",
       " ('month_cat', 0.19291087463795614),\n",
       " (34, 0.12028278864975765),\n",
       " ('restrictions_pct_change', 0.05603631997519233),\n",
       " ('amounts_pct_change', 0.03380167776681638),\n",
       " (21, 0.03177765576430872),\n",
       " (29, 0.023932380007048414),\n",
       " (24, 0.018662611367285132),\n",
       " (32, 0.016993626889220563),\n",
       " (36, 0.015537081230713939),\n",
       " ('min_amount_pct_change', 0.012793955421866603),\n",
       " (35, 0.009815434255650344),\n",
       " (15, 0.00857980406983099),\n",
       " ('req_fields_pct_change', 0.00642302412715855),\n",
       " ('collect_phone_pct_change', 0.005198724314321957),\n",
       " ('opt_fields_pct_change', 0.004989744157058197),\n",
       " ('pledges_count_pct_change', 0.004492707885422661),\n",
       " ('ded_types_pct_change', 0.0043731032159567505),\n",
       " ('collect_optin_pct_change', 0.004161012856302714)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = []\n",
    "for e in zip(X_train.columns, rf.feature_importances_):\n",
    "    feature_importances.append(e)\n",
    "sorted(feature_importances, key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance threshold: 1.00%\n",
      "\tscore: -0.1566\n",
      "\tmse: 1358.5875\n",
      "\tfeature count: 12\n",
      "Feature importance threshold: 2.00%\n",
      "\tscore: -0.1529\n",
      "\tmse: 1339.6120\n",
      "\tfeature count: 8\n",
      "Feature importance threshold: 5.00%\n",
      "\tscore: -0.1394\n",
      "\tmse: 1327.6880\n",
      "\tfeature count: 5\n",
      "Feature importance threshold: 10.00%\n",
      "\tscore: -0.1227\n",
      "\tmse: 1305.8301\n",
      "\tfeature count: 4\n",
      "Feature importance threshold: 15.00%\n",
      "\tscore: -0.0783\n",
      "\tmse: 1255.5223\n",
      "\tfeature count: 3\n"
     ]
    }
   ],
   "source": [
    "for threshold in [0.01, 0.02, 0.05, 0.1, 0.15]:\n",
    "    scores = []\n",
    "    mses = []\n",
    "    \n",
    "    for i in range(50):\n",
    "        # features with importances greater than 1%\n",
    "        features_gt_one = [c[0] for c in feature_importances if c[1] >= threshold]\n",
    "        target = 'new_rec_count_pct_change'\n",
    "\n",
    "        # build training data set\n",
    "        feature_cols = features_gt_one\n",
    "        this_dataset = dataset[feature_cols + [target]].fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset.drop(target, axis=1), this_dataset[target])\n",
    "\n",
    "        # fit & evaluate\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = rf.predict(X_test)\n",
    "\n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "        mses.append(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "    print(\"Feature importance threshold: {:.2f}%\".format(threshold * 100.))\n",
    "    print(\"\\tscore: {:.4f}\".format(np.mean(scores)))\n",
    "    print(\"\\tmse: {:.4f}\".format(np.mean(mses)))\n",
    "    print(\"\\tfeature count: {}\".format(len(features_gt_one)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.029187671075280974"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'count_growth'\n",
    "# build training data set\n",
    "feature_cols = [c for c in dataset.columns if c not in target_cols + ['week', 'form']]\n",
    "this_dataset = dataset[feature_cols + [target]].fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(this_dataset.drop(target, axis=1), this_dataset[target])\n",
    "\n",
    "# fit & evaluate\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('month_cat', 0.2898206330172784),\n",
       " (34, 0.27761555521016335),\n",
       " (23, 0.16888039243458336),\n",
       " (11, 0.0798658783509187),\n",
       " (29, 0.030887677361040016),\n",
       " ('opt_fields_pct_change', 0.027543045197842692),\n",
       " (35, 0.027346352145332542),\n",
       " (24, 0.019319812867044477),\n",
       " ('collect_optin_pct_change', 0.011871578446935758),\n",
       " ('restrictions_pct_change', 0.01179619559019152),\n",
       " ('enable_donorlogins_pct_change', 0.008955984965950198),\n",
       " ('amounts_pct_change', 0.007176280232531108),\n",
       " ('collect_phone_pct_change', 0.004770886939474752),\n",
       " (32, 0.004552895661607228),\n",
       " (21, 0.004301825156416668),\n",
       " ('min_amount_pct_change', 0.004258473531623267),\n",
       " ('ded_types_pct_change', 0.003934837963595551),\n",
       " (15, 0.0030973707643816204),\n",
       " ('collect_company_pct_change', 0.0025765889287081073),\n",
       " ('req_fields_pct_change', 0.0023556198081053333)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = []\n",
    "for e in zip(X_train.columns, rf.feature_importances_):\n",
    "    feature_importances.append(e)\n",
    "sorted(feature_importances, key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance threshold: 0.25%\n",
      "\tscore: -0.4859\n",
      "\tfeature count: 19\n",
      "Feature importance threshold: 0.50%\n",
      "\tscore: -0.6337\n",
      "\tfeature count: 12\n",
      "Feature importance threshold: 1.00%\n",
      "\tscore: -0.5751\n",
      "\tfeature count: 10\n",
      "Feature importance threshold: 2.00%\n",
      "\tscore: -0.2870\n",
      "\tfeature count: 7\n",
      "Feature importance threshold: 5.00%\n",
      "\tscore: -0.2545\n",
      "\tfeature count: 4\n",
      "Feature importance threshold: 10.00%\n",
      "\tscore: -0.2477\n",
      "\tfeature count: 3\n",
      "Feature importance threshold: 15.00%\n",
      "\tscore: -0.1976\n",
      "\tfeature count: 3\n"
     ]
    }
   ],
   "source": [
    "for threshold in [0.0025, 0.005, 0.01, 0.02, 0.05, 0.1, 0.15]:\n",
    "    scores = []\n",
    "    for i in range(100):\n",
    "        # features with importances greater than 1%\n",
    "        features_gt_one = [c[0] for c in feature_importances if c[1] >= threshold]\n",
    "        target = 'count_growth'\n",
    "\n",
    "        # build training data set\n",
    "        feature_cols = features_gt_one\n",
    "        this_dataset = dataset[feature_cols + [target]].fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset.drop(target, axis=1), this_dataset[target])\n",
    "\n",
    "        # fit & evaluate\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "        \n",
    "    print(\"Feature importance threshold: {:.2f}%\".format(threshold * 100.))\n",
    "    print(\"\\tscore: {:.4f}\".format(np.mean(scores)))\n",
    "    print(\"\\tfeature count: {}\".format(len(features_gt_one)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vol_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.270770951214371"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'vol_growth'\n",
    "# build training data set\n",
    "feature_cols = [c for c in dataset.columns if c not in target_cols + ['week', 'form']]\n",
    "this_dataset = dataset[feature_cols + [target]].fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(this_dataset.drop(target, axis=1), this_dataset[target])\n",
    "\n",
    "# fit & evaluate\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('month_cat', 0.408707560017338),\n",
       " (11, 0.12347990737398015),\n",
       " ('collect_optin_pct_change', 0.09537905488911888),\n",
       " (23, 0.08020489135295499),\n",
       " ('pledges_count_pct_change', 0.07836067503993673),\n",
       " (24, 0.06530791744960326),\n",
       " (34, 0.06345382286104032),\n",
       " ('amounts_pct_change', 0.01627468847484685),\n",
       " ('req_fields_pct_change', 0.015088511796333203),\n",
       " (36, 0.014683330093155408),\n",
       " ('ded_types_pct_change', 0.011371829201326686),\n",
       " ('donation_active_pct_change', 0.0060258678427350726),\n",
       " ('restrictions_pct_change', 0.005188176157896121),\n",
       " (29, 0.0037251316399992463),\n",
       " (32, 0.0035676702536430243),\n",
       " (21, 0.0016520942028775006),\n",
       " ('min_amount_pct_change', 0.0013757744453010297),\n",
       " ('permit_create_own_pledge_pct_change', 0.0013206235633018565),\n",
       " ('permit_other_amount_pct_change', 0.0009123324941325306),\n",
       " (35, 0.0006437386793393383)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = []\n",
    "for e in zip(X_train.columns, rf.feature_importances_):\n",
    "    feature_importances.append(e)\n",
    "sorted(feature_importances, key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance threshold: 0.25%\n",
      "\tscore: -3.1009\n",
      "\tfeature count: 15\n",
      "Feature importance threshold: 0.50%\n",
      "\tscore: -2.4128\n",
      "\tfeature count: 13\n",
      "Feature importance threshold: 1.00%\n",
      "\tscore: -2.6525\n",
      "\tfeature count: 11\n",
      "Feature importance threshold: 2.00%\n",
      "\tscore: -3.2317\n",
      "\tfeature count: 7\n",
      "Feature importance threshold: 5.00%\n",
      "\tscore: -3.2286\n",
      "\tfeature count: 7\n",
      "Feature importance threshold: 10.00%\n",
      "\tscore: -0.0702\n",
      "\tfeature count: 2\n",
      "Feature importance threshold: 15.00%\n",
      "\tscore: -0.0229\n",
      "\tfeature count: 1\n"
     ]
    }
   ],
   "source": [
    "for threshold in [0.0025, 0.005, 0.01, 0.02, 0.05, 0.1, 0.15]:\n",
    "    scores = []\n",
    "    for i in range(100):\n",
    "        # features with importances greater than 1%\n",
    "        features_gt_one = [c[0] for c in feature_importances if c[1] >= threshold]\n",
    "        target = 'vol_growth'\n",
    "\n",
    "        # build training data set\n",
    "        feature_cols = features_gt_one\n",
    "        this_dataset = dataset[feature_cols + [target]].fillna(0).replace(np.inf, 100.).replace(-np.inf, -100.)\n",
    "\n",
    "        # train/test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(this_dataset.drop(target, axis=1), this_dataset[target])\n",
    "\n",
    "        # fit & evaluate\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        scores.append(rf.score(X_test, y_test))\n",
    "        \n",
    "    print(\"Feature importance threshold: {:.2f}%\".format(threshold * 100.))\n",
    "    print(\"\\tscore: {:.4f}\".format(np.mean(scores)))\n",
    "    print(\"\\tfeature count: {}\".format(len(features_gt_one)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
